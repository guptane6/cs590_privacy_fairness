{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Much of this code was lifted from [the Conversation AI project](https://conversationai.github.io/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import model_bias_analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read TSVs from file. These are the original data from *Conversation AI*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = pd.read_csv(\"toxicity_annotated_comments.tsv\"\\\n",
    "                                          , sep = \"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = pd.read_csv(\"toxicity_annotations.tsv\"\\\n",
    "                                          , sep = \"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# toxicity_worker_demographics = pd.read_csv(\"toxicity_worker_demographics.tsv\"\\\n",
    "#                                           , sep = \"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* *grouped_annotations* takes the mean of all toxicity ratings of a comment.\n",
    "* *joined_tox* joins *grouped_annotations* and *comments*.\n",
    "* We also add a column *binary_tox* to the dataframe *joined_tox*. Here we assign a toxicity rating of 0 or 1 based on whether the mean toxicity rating is above or below 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_annotations = annotations.groupby('rev_id',as_index=False)['toxicity'].mean()\n",
    "joined_tox = grouped_annotations.join(comments, lsuffix='rev_id', rsuffix='rev_id', how='left', sort=True) \n",
    "joined_tox['binary_tox'] = np.where(joined_tox['toxicity']>=.5, 1, 0)\n",
    "\n",
    "# Stuff I might want later\n",
    "# # remove newline and tab tokens\n",
    "# comments['comment'] = comments['comment'].apply(lambda x: x.replace(\"NEWLINE_TOKEN\", \" \"))\n",
    "# comments['comment'] = comments['comment'].apply(lambda x: x.replace(\"TAB_TOKEN\", \" \"))\n",
    "# comments['length'] = comments['comment'].str.len()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train logistic regression classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test ROC AUC: 0.951\n"
     ]
    }
   ],
   "source": [
    "test_comments = joined_tox.query(\"split == 'test' \")\n",
    "train_comments = joined_tox.query(\"split == 'train' \")\n",
    "\n",
    "clf = Pipeline([\n",
    "    ('vect', CountVectorizer(max_features = 10000, ngram_range = (1,2))),\n",
    "    ('tfidf', TfidfTransformer(norm = 'l2')),\n",
    "    ('clf', LogisticRegression()),\n",
    "])\n",
    "\n",
    "clf = clf.fit(train_comments['comment'], train_comments['binary_tox'])\n",
    "auc = roc_auc_score(test_comments['binary_tox'], clf.predict_proba(test_comments['comment'])[:, 1])\n",
    "print('Test ROC AUC: %.3f' %auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Neha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "test_comments[\"predicted\"] = clf.predict(test_comments['comment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['rev_idrev_id', 'toxicity', 'rev_idrev_id', 'comment', 'year',\n",
       "       'logged_in', 'ns', 'sample', 'split', 'binary_tox', 'predicted'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_comments.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An example of a comment predicted to be toxic.\n",
    "# test_comments[test_comments['predicted'] == 1]['comment'][1649]#['comment']#.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rev_idrev_id</th>\n",
       "      <th>toxicity</th>\n",
       "      <th>rev_idrev_id</th>\n",
       "      <th>comment</th>\n",
       "      <th>year</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>ns</th>\n",
       "      <th>sample</th>\n",
       "      <th>split</th>\n",
       "      <th>binary_tox</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>5815399.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>5815399.0</td>\n",
       "      <td>NEWLINE_TOKENNEWLINE_TOKENIt was anonymous on ...</td>\n",
       "      <td>2004</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1227</th>\n",
       "      <td>8357736.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>8357736.0</td>\n",
       "      <td>NEWLINE_TOKENNEWLINE_TOKENYou are a child.</td>\n",
       "      <td>2004</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>blocked</td>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1228</th>\n",
       "      <td>8359431.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>8359431.0</td>\n",
       "      <td>`NEWLINE_TOKENNEWLINE_TOKEN::You are not worth...</td>\n",
       "      <td>2004</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>blocked</td>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1348</th>\n",
       "      <td>8845700.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8845700.0</td>\n",
       "      <td>NEWLINE_TOKENNEWLINE_TOKENi am using the sandb...</td>\n",
       "      <td>2004</td>\n",
       "      <td>False</td>\n",
       "      <td>user</td>\n",
       "      <td>blocked</td>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1521</th>\n",
       "      <td>9664203.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>9664203.0</td>\n",
       "      <td>NEWLINE_TOKENNEWLINE_TOKEN== whoa ==NEWLINE_TO...</td>\n",
       "      <td>2005</td>\n",
       "      <td>False</td>\n",
       "      <td>user</td>\n",
       "      <td>blocked</td>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      rev_idrev_id  toxicity  rev_idrev_id  \\\n",
       "829      5815399.0       0.7     5815399.0   \n",
       "1227     8357736.0       0.3     8357736.0   \n",
       "1228     8359431.0       0.5     8359431.0   \n",
       "1348     8845700.0       1.0     8845700.0   \n",
       "1521     9664203.0       0.8     9664203.0   \n",
       "\n",
       "                                                comment  year  logged_in  \\\n",
       "829   NEWLINE_TOKENNEWLINE_TOKENIt was anonymous on ...  2004       True   \n",
       "1227       NEWLINE_TOKENNEWLINE_TOKENYou are a child.    2004       True   \n",
       "1228  `NEWLINE_TOKENNEWLINE_TOKEN::You are not worth...  2004       True   \n",
       "1348  NEWLINE_TOKENNEWLINE_TOKENi am using the sandb...  2004      False   \n",
       "1521  NEWLINE_TOKENNEWLINE_TOKEN== whoa ==NEWLINE_TO...  2005      False   \n",
       "\n",
       "           ns   sample split  binary_tox  predicted  \n",
       "829   article   random  test           1          1  \n",
       "1227     user  blocked  test           0          1  \n",
       "1228     user  blocked  test           1          1  \n",
       "1348     user  blocked  test           1          1  \n",
       "1521     user  blocked  test           1          1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is what the predicted toxic=True test comments looks like after the prediction is done\n",
    "test_comments[test_comments['predicted'] == 1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "[1]\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "print(clf.predict(['Thanks for you contribution, you did a great job!']))\n",
    "# Model labels this comment as non-toxic.\n",
    "print(clf.predict(['People as stupid as you should not edit Wikipedia!']))\n",
    "# Model labels this comment as toxic.\n",
    "print(clf.predict(['I am a proud gay']))\n",
    "# Model also labels this comment as toxic. Uh-oh! We don't think this comment should be toxic!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Neha\\Documents\\GitHub\\cs590_privacy_fairness\\model_bias_analysis.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df[term] = df[text_column].apply(lambda x: bool(re.search(r'\\b{}\\b'.format(term), x, flags=re.IGNORECASE)))\n"
     ]
    }
   ],
   "source": [
    "# What are the identity labels?\n",
    "\n",
    "# Currently not in use, but possiblyl we'll want to use it later\n",
    "\n",
    "# TEST_TERMS = ['tall', 'wikipedia', 'teacher', 'music', 'box',\n",
    "#               'lesbian', 'gay', 'bisexual', 'transgender', 'queer',\n",
    "#               'homosexual', 'heterosexual', 'straight',\n",
    "#               'muslim', 'jewish', 'jew', 'christian',\n",
    "#               'feminist', 'black', 'white']\n",
    "\n",
    "madlibs_terms = model_bias_analysis.read_identity_terms('adjectives_people.txt')\n",
    "\n",
    "# Add identity labels to train and test comments\n",
    "model_bias_analysis.add_subgroup_columns_from_text(train_comments, 'comment', madlibs_terms)\n",
    "model_bias_analysis.add_subgroup_columns_from_text(test_comments, 'comment', madlibs_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the train and test if you wanna check that the identity label of terms were added\n",
    "# train_comments.head()\n",
    "# test_comments.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Equation DI:\n",
    "DI(t1,t2) = (probability that comment containing term t1 is labeled toxic) / (probability that comment containing term t2 is labelled toxic)\n",
    "= a/b\n",
    "\n",
    "a = # comments containing t1 AND toxic / # comments containing t1\n",
    "= alpha/beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confirm that you can find alpha\n",
    "train_comments[train_comments['lesbian'] == True].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confirm that you can find beta\n",
    "train_comments[(train_comments['lesbian'] == True) & (train_comments['binary_tox'] == 1)].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rev_idrev_id</th>\n",
       "      <th>toxicity</th>\n",
       "      <th>rev_idrev_id</th>\n",
       "      <th>comment</th>\n",
       "      <th>year</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>ns</th>\n",
       "      <th>sample</th>\n",
       "      <th>split</th>\n",
       "      <th>binary_tox</th>\n",
       "      <th>...</th>\n",
       "      <th>older</th>\n",
       "      <th>young</th>\n",
       "      <th>younger</th>\n",
       "      <th>teenage</th>\n",
       "      <th>millenial</th>\n",
       "      <th>middle aged</th>\n",
       "      <th>elderly</th>\n",
       "      <th>blind</th>\n",
       "      <th>deaf</th>\n",
       "      <th>paralyzed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2232.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2232.0</td>\n",
       "      <td>This:NEWLINE_TOKEN:One can make an analogy in ...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4216.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4216.0</td>\n",
       "      <td>`NEWLINE_TOKENNEWLINE_TOKEN:Clarification for ...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26547.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26547.0</td>\n",
       "      <td>`This is such a fun entry.   DevotchkaNEWLINE_...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>37330.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>37330.0</td>\n",
       "      <td>`NEWLINE_TOKENNEWLINE_TOKENNEWLINE_TOKENI fixe...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>37346.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>37346.0</td>\n",
       "      <td>`If they are ``indisputable`` then why does th...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   rev_idrev_id  toxicity  rev_idrev_id  \\\n",
       "0        2232.0       0.1        2232.0   \n",
       "1        4216.0       0.0        4216.0   \n",
       "3       26547.0       0.0       26547.0   \n",
       "6       37330.0       0.3       37330.0   \n",
       "7       37346.0       0.1       37346.0   \n",
       "\n",
       "                                             comment  year  logged_in  \\\n",
       "0  This:NEWLINE_TOKEN:One can make an analogy in ...  2002       True   \n",
       "1  `NEWLINE_TOKENNEWLINE_TOKEN:Clarification for ...  2002       True   \n",
       "3  `This is such a fun entry.   DevotchkaNEWLINE_...  2002       True   \n",
       "6  `NEWLINE_TOKENNEWLINE_TOKENNEWLINE_TOKENI fixe...  2002       True   \n",
       "7  `If they are ``indisputable`` then why does th...  2002       True   \n",
       "\n",
       "        ns  sample  split  binary_tox    ...      older  young  younger  \\\n",
       "0  article  random  train           0    ...      False  False    False   \n",
       "1     user  random  train           0    ...      False  False    False   \n",
       "3  article  random  train           0    ...      False  False    False   \n",
       "6  article  random  train           0    ...      False  False    False   \n",
       "7  article  random  train           0    ...      False  False    False   \n",
       "\n",
       "   teenage  millenial  middle aged  elderly  blind   deaf  paralyzed  \n",
       "0    False      False        False    False  False  False      False  \n",
       "1    False      False        False    False  False  False      False  \n",
       "3    False      False        False    False  False  False      False  \n",
       "6    False      False        False    False  False  False      False  \n",
       "7    False      False        False    False  False  False      False  \n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_comments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.39473684  0.62544803  0.07692308  0.26315789  0.0952381   0.74509804\n",
      "  0.07017544  1.          0.46774194  0.13702624  0.15789474  0.17073171\n",
      "  0.15577889 -1.          0.08474576  0.16326531  0.18042813  0.15853659\n",
      "  0.09090909  0.10416667  0.11111111  0.2        -1.          0.2739726\n",
      "  0.06944444  0.09857978  0.12        0.11444142  0.09090909  0.12058824\n",
      "  0.07216495  0.09190372  0.13057325  0.11860465  0.02173913  0.08906883\n",
      "  0.03846154  0.11111111 -1.          0.12916667  0.0472103   0.09433962\n",
      "  0.03529412  0.125       0.         -1.          0.          0.19496855\n",
      "  0.08       -1.        ]\n"
     ]
    }
   ],
   "source": [
    "def calculate_pairwise_di(df, madlibs_terms, colname):\n",
    "    \n",
    "    # We now calculate the DI for each pair for the training data.\n",
    "\n",
    "    term_toxicity = np.zeros(len(madlibs_terms))\n",
    "\n",
    "    # we temporarily put -1 in as a placeholder for stuff that has no exacmples of terms with that term.\n",
    "    # non-binary is one\n",
    "    for i in range(len(madlibs_terms)):\n",
    "        try:\n",
    "            term_toxicity[i] = float((df[(df[madlibs_terms[i]] == True) & (df[colname] == 1)].shape[0]))/  \\\n",
    "            float((df[df[madlibs_terms[i]] == True].shape[0]))\n",
    "        except ZeroDivisionError:\n",
    "            term_toxicity[i] = -1 \n",
    "\n",
    "    return term_toxicity\n",
    "\n",
    "term_toxicity = calculate_pairwise_di(train_comments, madlibs_terms, 'binary_tox')\n",
    "print(term_toxicity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46.0 (7, 34)\n",
      "lgbtq buddhist\n"
     ]
    }
   ],
   "source": [
    "# This finds the max DI between all pairs of identity terms, which for one of our experiments,\n",
    "# we're claiming is kind of the DI of all terms\n",
    "# Possibly something we'll take out or come back to once we try more versions of our code. (Neha's working on this!)\n",
    "\n",
    "def find_max_di(term_toxicity, madlibs_terms):\n",
    "    # General questions for potential problems with this method:\n",
    "    # Do we want the 0s? That would mean they are never used in a toxic way but can't divide by 0...\n",
    "    # Also, how often do terms appear? Is sample size crazy small right now?? \n",
    "    max_prop = 0\n",
    "    top_indexes = ()\n",
    "\n",
    "    for i in range(len(madlibs_terms)):\n",
    "        for j in range(len(madlibs_terms)):\n",
    "            if (i==j or term_toxicity[i] == -1 or term_toxicity[j] == -1 or term_toxicity[j] == 0):\n",
    "                continue\n",
    "            if term_toxicity[i]/ term_toxicity[j] > max_prop:\n",
    "                max_prop = term_toxicity[i]/ term_toxicity[j]\n",
    "                top_indexes = (i,j)\n",
    "                \n",
    "    return max_prop, top_indexes\n",
    "\n",
    "max_prop, top_indexes = find_max_di(term_toxicity, madlibs_terms)\n",
    "\n",
    "print(max_prop, top_indexes)\n",
    "print(madlibs_terms[7], madlibs_terms[34])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now! We do the same thing but for the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# alpha of test\n",
    "test_comments[test_comments['lesbian'] == True].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# beta of test\n",
    "test_comments[(test_comments['lesbian'] == True) & (test_comments['predicted'] == 1)].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This writes the 3 dataframes to csv so that we can read from that later for shorter code.\n",
    "\n",
    "joined_tox.to_csv('joined_tox.csv')\n",
    "train_comments.to_csv('train_comments.csv')\n",
    "test_comments.to_csv('test_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_comments = pd.read_csv('train_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_comments = pd.read_csv('test_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generates one perturbation.\n",
    "\n",
    "list_perturbation = []\n",
    "\n",
    "length = len(train_comments.binary_tox.values)\n",
    "for j in range(10):\n",
    "    rand = np.random.random(length) # generate a random number (between 0 and 1) for each comment\n",
    "    tox_tmp = np.copy(train_comments.binary_tox.values) # np.copy(tox_np)\n",
    "    for i in range(length):\n",
    "        if rand[i] >= 0.5: # if random number is greater than 0.5, replace value in array with a random integer from [0, 1]\n",
    "            tox_tmp[i] = np.random.randint(2)\n",
    "    list_perturbation.append(tox_tmp)\n",
    "\n",
    "# each item in list_perturbation is a list of 0s and 1s that correspond to the new binary_tox of each variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0, 1, 0, ..., 0, 0, 1], dtype=int64), array([1, 1, 0, ..., 0, 0, 1], dtype=int64), array([0, 0, 1, ..., 0, 0, 0], dtype=int64), array([0, 1, 0, ..., 0, 0, 1], dtype=int64), array([1, 1, 0, ..., 0, 0, 0], dtype=int64), array([1, 0, 0, ..., 0, 0, 0], dtype=int64), array([0, 1, 0, ..., 0, 0, 0], dtype=int64), array([0, 1, 0, ..., 0, 0, 0], dtype=int64), array([0, 1, 0, ..., 0, 0, 0], dtype=int64), array([1, 0, 1, ..., 0, 0, 0], dtype=int64)]\n"
     ]
    }
   ],
   "source": [
    "print(list_perturbation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** [(3.3, (21, 46)), (7.11764705882353, (5, 46)), (6.25, (44, 48)), (11.0, (7, 46)), (11.0, (7, 46)), (9.5, (7, 3)), (11.0, (7, 46)), (6.901960784313725, (5, 46)), (8.666666666666666, (7, 2)), (6.352941176470589, (5, 20))]\n"
     ]
    }
   ],
   "source": [
    "# Calculate max DIs on all of the perturbed training datasets\n",
    "\n",
    "training_data_dis = []\n",
    "\n",
    "for i in range(10):\n",
    "    train_comments['newcol'] = list_perturbation[i]\n",
    "    term_toxicity = calculate_pairwise_di(train_comments, madlibs_terms, 'newcol')\n",
    "    max_prop, top_indexes = find_max_di(term_toxicity, madlibs_terms)\n",
    "    training_data_dis.append((max_prop, top_indexes))\n",
    "\n",
    "print(\"**\", training_data_dis)\n",
    "# This is the array of all of the max_dis, and the indexes of the madlibs_terms array that composed that max_di"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test ROC AUC: 0.88699\n",
      "Test ROC AUC: 0.89348\n",
      "Test ROC AUC: 0.88652\n",
      "Test ROC AUC: 0.88795\n",
      "Test ROC AUC: 0.88485\n",
      "Test ROC AUC: 0.88355\n",
      "Test ROC AUC: 0.88990\n",
      "Test ROC AUC: 0.88771\n",
      "Test ROC AUC: 0.88754\n",
      "Test ROC AUC: 0.88733\n"
     ]
    }
   ],
   "source": [
    "# This trains a classifier on n different perturbed datsets \n",
    "\n",
    "d={}\n",
    "n = 10\n",
    "for x in range(n):\n",
    "    d[\"clf{0}\".format(x)] = Pipeline([\n",
    "        ('vect', CountVectorizer(max_features = 10000, ngram_range = (1,2))),\n",
    "        ('tfidf', TfidfTransformer(norm = 'l2')),\n",
    "        ('clf', LogisticRegression()),\n",
    "    ])\n",
    "    d[\"clf{0}\".format(x)] = d[\"clf{0}\".format(x)].\\\n",
    "                                fit(train_comments['comment'], list_perturbation[x])\n",
    "    d[\"auc{0}\".format(x)] = roc_auc_score(test_comments['binary_tox'], \\\n",
    "                                d[\"clf{0}\".format(x)].predict_proba(test_comments['comment'])[:, 1])\n",
    "    print('Test ROC AUC: %.5f' %d[\"auc{0}\".format(x)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once a classifier is trained, this goes to the test data and creates predictions on test data\n",
    "perturbed_predictions = [] # list, each item is array of predictions. element 0 is 0th perturbation and \n",
    "# predictions based on that.\n",
    "# each item in the array is a column that indicates 0/1 for predicted not-toxic/toxic\n",
    "\n",
    "for i in range(10):\n",
    "    perturbed_predictions.append(d[\"clf{0}\".(i)].predict(test_comments['comment']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0, 0, 0, ..., 0, 0, 0], dtype=int64), array([0, 0, 0, ..., 0, 0, 0], dtype=int64), array([0, 0, 0, ..., 0, 0, 0], dtype=int64), array([0, 0, 0, ..., 0, 0, 0], dtype=int64), array([0, 0, 0, ..., 0, 0, 0], dtype=int64), array([0, 1, 0, ..., 0, 0, 0], dtype=int64), array([0, 0, 0, ..., 0, 0, 0], dtype=int64), array([0, 0, 0, ..., 0, 0, 0], dtype=int64), array([0, 1, 0, ..., 0, 0, 0], dtype=int64), array([0, 0, 0, ..., 0, 0, 0], dtype=int64)]\n"
     ]
    }
   ],
   "source": [
    "print(perturbed_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28249  3617]\n",
      "[29459  2407]\n",
      "[29343  2523]\n",
      "[29411  2455]\n",
      "[29523  2343]\n",
      "[29397  2469]\n",
      "[29474  2392]\n",
      "[29343  2523]\n",
      "[29377  2489]\n",
      "[29395  2471]\n",
      "[29418  2448]\n"
     ]
    }
   ],
   "source": [
    "# Sanity check\n",
    "print(np.bincount(test_comments.binary_tox.values))\n",
    "# More sanity\n",
    "for arr in perturbed_predictions:\n",
    "    print(np.bincount(arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Goal: Compute fairness on test dataset.\n",
    "\n",
    "test_comments['newcol'] = perturbed_predictions[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>rev_idrev_id</th>\n",
       "      <th>toxicity</th>\n",
       "      <th>rev_idrev_id.1</th>\n",
       "      <th>comment</th>\n",
       "      <th>year</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>ns</th>\n",
       "      <th>sample</th>\n",
       "      <th>split</th>\n",
       "      <th>...</th>\n",
       "      <th>young</th>\n",
       "      <th>younger</th>\n",
       "      <th>teenage</th>\n",
       "      <th>millenial</th>\n",
       "      <th>middle aged</th>\n",
       "      <th>elderly</th>\n",
       "      <th>blind</th>\n",
       "      <th>deaf</th>\n",
       "      <th>paralyzed</th>\n",
       "      <th>newcol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>8953.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8953.0</td>\n",
       "      <td>Elected or Electoral? JHK</td>\n",
       "      <td>2002</td>\n",
       "      <td>False</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>28959.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>28959.0</td>\n",
       "      <td>Please relate the ozone hole to increases in c...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19</td>\n",
       "      <td>138074.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>138074.0</td>\n",
       "      <td>`NEWLINE_TOKENNEWLINE_TOKENNEWLINE_TOKENNEWLIN...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>200664.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200664.0</td>\n",
       "      <td>NEWLINE_TOKENNEWLINE_TOKENNEWLINE_TOKEN NEWLIN...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37</td>\n",
       "      <td>213105.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>213105.0</td>\n",
       "      <td>`NEWLINE_TOKENNEWLINE_TOKEN: I should do that ...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  rev_idrev_id  toxicity  rev_idrev_id.1  \\\n",
       "0           2        8953.0       0.0          8953.0   \n",
       "1           4       28959.0       0.2         28959.0   \n",
       "2          19      138074.0       0.0        138074.0   \n",
       "3          33      200664.0       0.0        200664.0   \n",
       "4          37      213105.0       0.0        213105.0   \n",
       "\n",
       "                                             comment  year  logged_in  \\\n",
       "0                          Elected or Electoral? JHK  2002      False   \n",
       "1  Please relate the ozone hole to increases in c...  2002       True   \n",
       "2  `NEWLINE_TOKENNEWLINE_TOKENNEWLINE_TOKENNEWLIN...  2002       True   \n",
       "3  NEWLINE_TOKENNEWLINE_TOKENNEWLINE_TOKEN NEWLIN...  2002       True   \n",
       "4  `NEWLINE_TOKENNEWLINE_TOKEN: I should do that ...  2002       True   \n",
       "\n",
       "        ns  sample split   ...    young  younger  teenage  millenial  \\\n",
       "0  article  random  test   ...    False    False    False      False   \n",
       "1  article  random  test   ...    False    False    False      False   \n",
       "2  article  random  test   ...    False    False    False      False   \n",
       "3     user  random  test   ...    False    False    False      False   \n",
       "4     user  random  test   ...    False    False    False      False   \n",
       "\n",
       "   middle aged  elderly  blind   deaf  paralyzed  newcol  \n",
       "0        False    False  False  False      False       0  \n",
       "1        False    False  False  False      False       0  \n",
       "2        False    False  False  False      False       0  \n",
       "3        False    False  False  False      False       0  \n",
       "4        False    False  False  False      False       0  \n",
       "\n",
       "[5 rows x 63 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_comments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    29459\n",
       "1     2407\n",
       "Name: newcol, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check: Run these two lines below to confirm that they shape of newcol looks like perturbed_predictions array that you added\n",
    "test_comments['newcol'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2407"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(perturbed_predictions[0] == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** [(40.25, (45, 31)), (66.19354838709678, (1, 35)), (17.5, (20, 11)), (20.564516129032256, (1, 40)), (31.006451612903227, (1, 35)), (18.956451612903226, (1, 31)), (19.277419354838713, (1, 35)), (108.0, (45, 35)), (108.0, (45, 35)), (21.38494623655914, (1, 9))]\n"
     ]
    }
   ],
   "source": [
    "# For each of the perturbed_predictions, append it onto the dataset, find the pairwise DI, and then find the max DI.\n",
    "test_data_dis = []\n",
    "\n",
    "for i in range(len(perturbed_predictions)):\n",
    "    test_comments['newcol'] = perturbed_predictions[i]\n",
    "    term_toxicity = calculate_pairwise_di(test_comments, madlibs_terms, 'newcol')\n",
    "    max_prop, top_indexes = find_max_di(term_toxicity, madlibs_terms)\n",
    "    test_data_dis.append((max_prop, top_indexes))\n",
    "\n",
    "print(\"**\", test_data_dis)\n",
    "# This is the array of all of the max_dis, and the indexes of the madlibs_terms array that composed that max_di"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40.25 (45, 31)\n",
      "lgbtq buddhist\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neha's notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"This data set (https://figshare.com/articles/Wikipedia_Talk_Labels_Toxicity/4563973) includes over 100k labeled discussion comments from English Wikipedia. Each comment was labeled by multiple annotators via Crowdflower on whether it is a toxic or healthy contribution. We also include some demographic data for each crowd-worker. See our wiki for documentation of the schema of each file and our research paper for documentation on the data collection and modeling methodology. For a quick demo of how to use the data for model building and analysis, check out this ipython notebook.\" - quote from linked page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = pd.read_csv(\"toxicity_annotated_comments.tsv\"\\\n",
    "                                          , sep = \"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copied from documentation: <br>\n",
    "\"Schema for {attack/aggression/toxicity}_annotated_comments.tsv\n",
    "The comment text and metadata for comments with attack/aggression/toxicity labels generated by crowd-workers. The actual labels are in the corresponding {attack/aggression/toxicity}_annotations.tsv since each comment was labeled multiple times.\n",
    "\n",
    "rev_id: MediaWiki revision id of the edit that added the comment to a talk page (i.e. discussion). <br>\n",
    "comment: Comment text. Consists of the concatenation of content added during a revision/edit of a talk page. MediaWiki markup and HTML have been stripped out. To simplify tsv parsing, \\n has been mapped to NEWLINE_TOKEN, \\t has been mapped to TAB_TOKEN and \" has been mapped to `. <br>\n",
    "year: The year the comment was posted in. <br>\n",
    "logged_in: Indicator for whether the user who made the comment was logged in. Takes on values in {0, 1}. <br>\n",
    "ns: Namespace of the discussion page the comment was made in. Takes on values in {user, article}. <br>\n",
    "sample: Indicates whether the comment came via random sampling of all comments, or whether it came from random sampling of the 5 comments around a block event for violating WP:npa or WP:HA. Takes on values in {random, blocked}. <br>\n",
    "split: For model building in our paper we split comments into train, dev and test sets. Takes on values in {train, dev, test}.\"\n",
    "<br>\n",
    "\n",
    "My notes: <br> \n",
    "I don't know enough about how natural language processing works, but from the snippets that I do know, I imagine that the really really long comments probably aren't very good at being classified even. I also wonder about how bigram toxicity works and whether this is something the training data accounts for (eg \"nasty woman\" vs \"nasty\" has different sources of problems). What are they classifying on/why does this work? We can see Figure 1 in the Dixon paper for comment length and should be able to filter there. I wonder if the phrase templating of classification works for the problems that I raise of large comment length and bigrams. Is this an issue we should be dealing with?\n",
    "Also, an easier couple of questions are: what does the ns and sample really mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rev_id</th>\n",
       "      <th>comment</th>\n",
       "      <th>year</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>ns</th>\n",
       "      <th>sample</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2232.0</td>\n",
       "      <td>This:NEWLINE_TOKEN:One can make an analogy in ...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4216.0</td>\n",
       "      <td>`NEWLINE_TOKENNEWLINE_TOKEN:Clarification for ...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8953.0</td>\n",
       "      <td>Elected or Electoral? JHK</td>\n",
       "      <td>2002</td>\n",
       "      <td>False</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26547.0</td>\n",
       "      <td>`This is such a fun entry.   DevotchkaNEWLINE_...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28959.0</td>\n",
       "      <td>Please relate the ozone hole to increases in c...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rev_id                                            comment  year  \\\n",
       "0   2232.0  This:NEWLINE_TOKEN:One can make an analogy in ...  2002   \n",
       "1   4216.0  `NEWLINE_TOKENNEWLINE_TOKEN:Clarification for ...  2002   \n",
       "2   8953.0                          Elected or Electoral? JHK  2002   \n",
       "3  26547.0  `This is such a fun entry.   DevotchkaNEWLINE_...  2002   \n",
       "4  28959.0  Please relate the ozone hole to increases in c...  2002   \n",
       "\n",
       "   logged_in       ns  sample  split  \n",
       "0       True  article  random  train  \n",
       "1       True     user  random  train  \n",
       "2      False  article  random   test  \n",
       "3       True  article  random  train  \n",
       "4       True  article  random   test  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copied from documentation:\n",
    "        Schema for toxicity_annotations.tsv\n",
    "    Toxicity labels from several crowd-workers for each comment in toxicity_annotated_comments.tsv. It can be joined with toxicity_annotated_comments.tsv on rev_id.\n",
    "\n",
    "rev_id: MediaWiki revision id of the edit that added the comment to a talk page (i.e. discussion). <br>\n",
    "worker_id: Anonymized crowd-worker id.<br>\n",
    "toxicity_score: Categorical variable ranging from very toxic (-2), to neutral (0), to very healthy (2). <br>\n",
    "toxicity: Indicator variable for whether the worker thought the comment is toxic. The annotation takes on the value 1 if the worker considered the comment toxic (i.e worker gave a toxicity_score less than 0) and value 0 if the worker considered the comment neutral or healthy (i.e worker gave a toxicity_score greater or equal to 0). Takes on values in {0, 1}.\n",
    "\n",
    "My notes:\n",
    "Things to explore is how many people rated each thing? The paper said 10, but I would like to confirm this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = pd.read_csv(\"toxicity_annotations.tsv\"\\\n",
    "                                          , sep = \"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My comment:\n",
    "    This isn't really one we'll be using until much later, if/when we decide we're doing a perturbation using demographic data. Would first want to check to see what kind of correlations might/do exist between gender/rating and see how they rate comments about women, for example.\n",
    "    \n",
    "\n",
    "Copied from documentation:\n",
    "\n",
    "Schema for {attack/aggression/toxicity}_worker_demographics.tsv\n",
    "Demographic information about the crowdworkers. This information was obtained by an optional demographic survey administered after the labelling task. It is meant to be joined with {attack/aggression/toxicity}_annotations.tsv on worker_id. Some fields may be blank if left unanswered.\n",
    "\n",
    "worker_id: Anonymized crowd-worker id. <br>\n",
    "gender: The gender of the crowd-worker. Takes a value in {'male', 'female', and 'other'}. <br>\n",
    "english_first_language: Does the crowd-worker describe English as their first language. Takes a value in {0, 1}.<br>\n",
    "age_group: The age group of the crowd-worker. Takes on values in {'Under 18', '18-30', '30-45', '45-60', 'Over 60'}.<br>\n",
    "education: The highest education level obtained by the crowd-worker. Takes on values in {'none', 'some', 'hs', 'bachelors', 'masters', 'doctorate', 'professional'}. Here 'none' means no schooling, some means 'some schooling', 'hs' means high school completion, and the remaining terms indicate completion of the corresponding degree type.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
