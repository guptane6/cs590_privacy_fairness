{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Much of this code was lifted from [the Conversation AI project](https://conversationai.github.io/). In this file, I want to do DI vs gay on the y axis and threshold of toxicity on the x axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import model_bias_analysis\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_files(THRESHOLD_BINARY_TOXICITY):\n",
    "    comments = pd.read_csv(\"toxicity_annotated_comments.tsv\"\\\n",
    "                                          , sep = \"\\t\")\n",
    "    annotations = pd.read_csv(\"toxicity_annotations.tsv\"\\\n",
    "                                          , sep = \"\\t\")\n",
    "    # toxicity_worker_demographics = pd.read_csv(\"toxicity_worker_demographics.tsv\"\\\n",
    "#                                           , sep = \"\\t\")\n",
    "    grouped_annotations = annotations.groupby('rev_id',as_index=False)['toxicity'].mean()\n",
    "    joined_tox = grouped_annotations.join(comments, lsuffix='rev_id', rsuffix='rev_id', how='left', sort=True) \n",
    "    joined_tox['binary_tox'] = np.where(joined_tox['toxicity']>=THRESHOLD_BINARY_TOXICITY, 1, 0)\n",
    "    \n",
    "    # remove newline and tab tokens\n",
    "    joined_tox['comment'] = joined_tox.comment.apply(lambda x: x.replace('NEWLINE_TOKEN', '').replace('TAB_TOKEN', ''))\n",
    "    joined_tox['len_comment'] = joined_tox.comment.apply(lambda x: len(x))\n",
    "    \n",
    "    return joined_tox\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_test_train(joined_tox):\n",
    "    test_comments = joined_tox.query(\"split == 'test' \")\n",
    "    train_comments = joined_tox.query(\"split == 'train' \")\n",
    "    \n",
    "    return test_comments, train_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_identity_terms(test_comments, train_comments):\n",
    "\n",
    "    # Currently not in use, but possibly we'll switch to use this later\n",
    "\n",
    "    # TEST_TERMS = ['tall', 'wikipedia', 'teacher', 'music', 'box',\n",
    "    #               'lesbian', 'gay', 'bisexual', 'transgender', 'queer',\n",
    "    #               'homosexual', 'heterosexual', 'straight',\n",
    "    #               'muslim', 'jewish', 'jew', 'christian',\n",
    "    #               'feminist', 'black', 'white']\n",
    "\n",
    "    madlibs_terms = model_bias_analysis.read_identity_terms('adjectives_people.txt')\n",
    "\n",
    "    # Add identity labels to train and test comments\n",
    "    model_bias_analysis.add_subgroup_columns_from_text(train_comments, 'comment', madlibs_terms)\n",
    "    model_bias_analysis.add_subgroup_columns_from_text(test_comments, 'comment', madlibs_terms)\n",
    "    \n",
    "    return madlibs_terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* *grouped_annotations* takes the mean of all toxicity ratings of a comment.\n",
    "* *joined_tox* joins *grouped_annotations* and *comments*.\n",
    "* We also add a column *binary_tox* to the dataframe *joined_tox*. Here we assign a toxicity rating of 0 or 1 based on whether the mean toxicity rating is above or below 0.5 (or other value determined by threshold_binary_toxicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Neha\\Documents\\GitHub\\cs590_privacy_fairness\\model_bias_analysis.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df[term] = df[text_column].apply(lambda x: bool(re.search(r'\\b{}\\b'.format(term), x, flags=re.IGNORECASE)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with  30\n",
      "Done with  35\n",
      "Done with  40\n",
      "Done with  45\n",
      "Done with  50\n",
      "Done with  55\n",
      "Done with  60\n",
      "Done with  65\n",
      "Done with  70\n",
      "Done with  75\n",
      "Done with  80\n",
      "Done with  85\n",
      "Done with  90\n"
     ]
    }
   ],
   "source": [
    "for i in range(30,95,5):\n",
    "    joined_tox = read_files(i*0.01)\n",
    "    test_comments, train_comments = split_test_train(joined_tox)\n",
    "    madlibs_terms = add_identity_terms(test_comments, train_comments)\n",
    "\n",
    "    # This writes the 3 dataframes to csv so that we can read from that later for shorter code.\n",
    "    joined_tox.to_csv('joined_tox'+str(i)+'.csv')\n",
    "    train_comments.to_csv('train_comments'+str(i)+'.csv')\n",
    "    test_comments.to_csv('test_comments'+str(i)+'.csv')\n",
    "    print(\"Done with \",i)\n",
    "# That (above) reads all of the actual files and generates df's\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
