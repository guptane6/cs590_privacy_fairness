{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import model_bias_analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Commented out because I believe we're not using these files right now. \n",
    "\n",
    "# toxicity_debiasing_data = pd.read_csv(\"toxicity_debiasing_data.tsv\", sep='\\t')\n",
    "# # review_id, comment, is toxic or not, split (train or test)\n",
    "\n",
    "# toxicity_debiasing_data_random = pd.read_csv(\"toxicity_debiasing_data_random.tsv\", sep = '\\t')\n",
    "# # review_id, comment, is toxic or not, split (train or test)\n",
    "\n",
    "# wiki_debias_dev = pd.read_csv(\"wiki_debias_dev.csv\") \n",
    "# # comment,is_toxic,logged_in,ns,rev_id,sample,split,toxicity,year\n",
    "\n",
    "# wiki_debias_random_dev = pd.read_csv(\"wiki_debias_random_dev.csv\")\n",
    "# # comment,is_toxic,logged_in,ns,rev_id,sample,split,toxicity,year\n",
    "\n",
    "# wiki_debias_random_test = pd.read_csv(\"wiki_debias_random_test.csv\")\n",
    "# # comment,is_toxic,logged_in,ns,rev_id,sample,split,toxicity,year\n",
    "\n",
    "#toxicity_debiasing_data.shape#.head\n",
    "#toxicity_debiasing_data_random.shape\n",
    "#wiki_debias_dev.shape\n",
    "#wiki_debias_random_dev.shape\n",
    "#wiki_debias_random_test.shape\n",
    "#sum(toxicity_debiasing_data['split'] == \"test\")/sum(toxicity_debiasing_data['split'] == \"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data set (https://figshare.com/articles/Wikipedia_Talk_Labels_Toxicity/4563973) includes over 100k labeled discussion comments from English Wikipedia. Each comment was labeled by multiple annotators via Crowdflower on whether it is a toxic or healthy contribution. We also include some demographic data for each crowd-worker. See our wiki for documentation of the schema of each file and our research paper for documentation on the data collection and modeling methodology. For a quick demo of how to use the data for model building and analysis, check out this ipython notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = pd.read_csv(\"toxicity_annotated_comments.tsv\"\\\n",
    "                                          , sep = \"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copied from documentation: <br>\n",
    "\"Schema for {attack/aggression/toxicity}_annotated_comments.tsv\n",
    "The comment text and metadata for comments with attack/aggression/toxicity labels generated by crowd-workers. The actual labels are in the corresponding {attack/aggression/toxicity}_annotations.tsv since each comment was labeled multiple times.\n",
    "\n",
    "rev_id: MediaWiki revision id of the edit that added the comment to a talk page (i.e. discussion). <br>\n",
    "comment: Comment text. Consists of the concatenation of content added during a revision/edit of a talk page. MediaWiki markup and HTML have been stripped out. To simplify tsv parsing, \\n has been mapped to NEWLINE_TOKEN, \\t has been mapped to TAB_TOKEN and \" has been mapped to `. <br>\n",
    "year: The year the comment was posted in. <br>\n",
    "logged_in: Indicator for whether the user who made the comment was logged in. Takes on values in {0, 1}. <br>\n",
    "ns: Namespace of the discussion page the comment was made in. Takes on values in {user, article}. <br>\n",
    "sample: Indicates whether the comment came via random sampling of all comments, or whether it came from random sampling of the 5 comments around a block event for violating WP:npa or WP:HA. Takes on values in {random, blocked}. <br>\n",
    "split: For model building in our paper we split comments into train, dev and test sets. Takes on values in {train, dev, test}.\"\n",
    "<br>\n",
    "\n",
    "My notes: <br> \n",
    "I don't know enough about how natural language processing works, but from the snippets that I do know, I imagine that the really really long comments probably aren't very good at being classified even. I also wonder about how bigram toxicity works and whether this is something the training data accounts for (eg \"nasty woman\" vs \"nasty\" has different sources of problems). What are they classifying on/why does this work? We can see Figure 1 in the Dixon paper for comment length and should be able to filter there. I wonder if the phrase templating of classification works for the problems that I raise of large comment length and bigrams. Is this an issue we should be dealing with?\n",
    "Also, an easier couple of questions are: what does the ns and sample really mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rev_id</th>\n",
       "      <th>comment</th>\n",
       "      <th>year</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>ns</th>\n",
       "      <th>sample</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2232.0</td>\n",
       "      <td>This:NEWLINE_TOKEN:One can make an analogy in ...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4216.0</td>\n",
       "      <td>`NEWLINE_TOKENNEWLINE_TOKEN:Clarification for ...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8953.0</td>\n",
       "      <td>Elected or Electoral? JHK</td>\n",
       "      <td>2002</td>\n",
       "      <td>False</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26547.0</td>\n",
       "      <td>`This is such a fun entry.   DevotchkaNEWLINE_...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28959.0</td>\n",
       "      <td>Please relate the ozone hole to increases in c...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rev_id                                            comment  year  \\\n",
       "0   2232.0  This:NEWLINE_TOKEN:One can make an analogy in ...  2002   \n",
       "1   4216.0  `NEWLINE_TOKENNEWLINE_TOKEN:Clarification for ...  2002   \n",
       "2   8953.0                          Elected or Electoral? JHK  2002   \n",
       "3  26547.0  `This is such a fun entry.   DevotchkaNEWLINE_...  2002   \n",
       "4  28959.0  Please relate the ozone hole to increases in c...  2002   \n",
       "\n",
       "   logged_in       ns  sample  split  \n",
       "0       True  article  random  train  \n",
       "1       True     user  random  train  \n",
       "2      False  article  random   test  \n",
       "3       True  article  random  train  \n",
       "4       True  article  random   test  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = pd.read_csv(\"toxicity_annotations.tsv\"\\\n",
    "                                          , sep = \"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copied from documentation:\n",
    "        Schema for toxicity_annotations.tsv\n",
    "    Toxicity labels from several crowd-workers for each comment in toxicity_annotated_comments.tsv. It can be joined with toxicity_annotated_comments.tsv on rev_id.\n",
    "\n",
    "rev_id: MediaWiki revision id of the edit that added the comment to a talk page (i.e. discussion). <br>\n",
    "worker_id: Anonymized crowd-worker id.<br>\n",
    "toxicity_score: Categorical variable ranging from very toxic (-2), to neutral (0), to very healthy (2). <br>\n",
    "toxicity: Indicator variable for whether the worker thought the comment is toxic. The annotation takes on the value 1 if the worker considered the comment toxic (i.e worker gave a toxicity_score less than 0) and value 0 if the worker considered the comment neutral or healthy (i.e worker gave a toxicity_score greater or equal to 0). Takes on values in {0, 1}.\n",
    "\n",
    "My notes:\n",
    "Things to explore is how many people rated each thing? The paper said 10, but I would like to confirm this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rev_id</th>\n",
       "      <th>worker_id</th>\n",
       "      <th>toxicity</th>\n",
       "      <th>toxicity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2232.0</td>\n",
       "      <td>723</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2232.0</td>\n",
       "      <td>4000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2232.0</td>\n",
       "      <td>3989</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2232.0</td>\n",
       "      <td>3341</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2232.0</td>\n",
       "      <td>1574</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rev_id  worker_id  toxicity  toxicity_score\n",
       "0  2232.0        723         0             0.0\n",
       "1  2232.0       4000         0             0.0\n",
       "2  2232.0       3989         0             1.0\n",
       "3  2232.0       3341         0             0.0\n",
       "4  2232.0       1574         0             1.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "toxicity_worker_demographics = pd.read_csv(\"toxicity_worker_demographics.tsv\"\\\n",
    "                                          , sep = \"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My comment:\n",
    "    This isn't really one we'll be using until much later, if/when we decide we're doing a perturbation using demographic data. Would first want to check to see what kind of correlations might/do exist between gender/rating and see how they rate comments about women, for example.\n",
    "    \n",
    "\n",
    "Copied from documentation:\n",
    "\n",
    "Schema for {attack/aggression/toxicity}_worker_demographics.tsv\n",
    "Demographic information about the crowdworkers. This information was obtained by an optional demographic survey administered after the labelling task. It is meant to be joined with {attack/aggression/toxicity}_annotations.tsv on worker_id. Some fields may be blank if left unanswered.\n",
    "\n",
    "worker_id: Anonymized crowd-worker id. <br>\n",
    "gender: The gender of the crowd-worker. Takes a value in {'male', 'female', and 'other'}. <br>\n",
    "english_first_language: Does the crowd-worker describe English as their first language. Takes a value in {0, 1}.<br>\n",
    "age_group: The age group of the crowd-worker. Takes on values in {'Under 18', '18-30', '30-45', '45-60', 'Over 60'}.<br>\n",
    "education: The highest education level obtained by the crowd-worker. Takes on values in {'none', 'some', 'hs', 'bachelors', 'masters', 'doctorate', 'professional'}. Here 'none' means no schooling, some means 'some schooling', 'hs' means high school completion, and the remaining terms indicate completion of the corresponding degree type.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>worker_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>english_first_language</th>\n",
       "      <th>age_group</th>\n",
       "      <th>education</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>85</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>18-30</td>\n",
       "      <td>bachelors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1617</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>45-60</td>\n",
       "      <td>bachelors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1394</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bachelors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>311</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>30-45</td>\n",
       "      <td>bachelors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1980</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>45-60</td>\n",
       "      <td>masters</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   worker_id  gender  english_first_language age_group  education\n",
       "0         85  female                       0     18-30  bachelors\n",
       "1       1617  female                       0     45-60  bachelors\n",
       "2       1394  female                       0       NaN  bachelors\n",
       "3        311    male                       0     30-45  bachelors\n",
       "4       1980    male                       0     45-60    masters"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxicity_worker_demographics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Stuff I tried that didn't work and I might want later\n",
    "\n",
    "# This code is copy/pasted from https://github.com/conversationai/unintended-ml-bias-analysis/blob/master/unintended_ml_bias/Dataset_bias_analysis.ipynb\n",
    "# grouped_ds = annotations.groupby('rev_id')['toxicity'].mean()\n",
    "# df = comments\n",
    "# df['toxic'] = annotations.groupby('rev_id')['toxicity'].mean() # > 0.5\n",
    "\n",
    "grouped_annotations = annotations.groupby('rev_id',as_index=False)['toxicity'].mean()\n",
    "joined_tox = grouped_annotations.join(comments, lsuffix='rev_id', rsuffix='rev_id', how='left', sort=True) \n",
    "joined_tox['binary_tox'] = np.where(joined_tox['toxicity']>=.5, 1, 0)\n",
    "# Stuff I might want later\n",
    "\n",
    "# # remove newline and tab tokens\n",
    "# comments['comment'] = comments['comment'].apply(lambda x: x.replace(\"NEWLINE_TOKEN\", \" \"))\n",
    "# comments['comment'] = comments['comment'].apply(lambda x: x.replace(\"TAB_TOKEN\", \" \"))\n",
    "# comments['length'] = comments['comment'].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    159686.000000\n",
       "mean          0.145049\n",
       "std           0.253866\n",
       "min           0.000000\n",
       "25%           0.000000\n",
       "50%           0.000000\n",
       "75%           0.200000\n",
       "max           1.000000\n",
       "Name: toxicity, dtype: float64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_tox['toxicity'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    141289\n",
       "1     18397\n",
       "Name: binary_tox, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_tox['binary_tox'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test ROC AUC: 0.951\n"
     ]
    }
   ],
   "source": [
    "test_comments = joined_tox.query(\"split == 'test' \")\n",
    "train_comments = joined_tox.query(\"split == 'train' \")\n",
    "\n",
    "clf = Pipeline([\n",
    "    ('vect', CountVectorizer(max_features = 10000, ngram_range = (1,2))),\n",
    "    ('tfidf', TfidfTransformer(norm = 'l2')),\n",
    "    ('clf', LogisticRegression()),\n",
    "])\n",
    "clf = clf.fit(train_comments['comment'], train_comments['binary_tox'])\n",
    "auc = roc_auc_score(test_comments['binary_tox'], clf.predict_proba(test_comments['comment'])[:, 1])\n",
    "print('Test ROC AUC: %.3f' %auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yujingke/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "test_comments[\"predicted\"] = clf.predict(test_comments['comment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Wait a minute.  I looked at your background and I see that you are French.  I sorry.  What's it like living in a former world power that is nothing but an impotent, second-rate country with an inferiority complex???  Wait don't tell me, from your comment I already know.  It tees you off that no one and I mean no one pays any damn attention to you any more, so much so that you have to buy Saddam's oil off of the black market and invade third world countries like the Ivory Coast and then lecture Americans.  But Americans do care!!!!  We just laugh at you.  Have Frog Day!!! NEWLINE_TOKENNEWLINE_TOKEN\""
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_comments[test_comments['predicted'] == 1]['comment'][1649]#['comment']#.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rev_idrev_id</th>\n",
       "      <th>toxicity</th>\n",
       "      <th>rev_idrev_id</th>\n",
       "      <th>comment</th>\n",
       "      <th>year</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>ns</th>\n",
       "      <th>sample</th>\n",
       "      <th>split</th>\n",
       "      <th>binary_tox</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>5815399.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>5815399.0</td>\n",
       "      <td>NEWLINE_TOKENNEWLINE_TOKENIt was anonymous on ...</td>\n",
       "      <td>2004</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1227</th>\n",
       "      <td>8357736.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>8357736.0</td>\n",
       "      <td>NEWLINE_TOKENNEWLINE_TOKENYou are a child.</td>\n",
       "      <td>2004</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>blocked</td>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1228</th>\n",
       "      <td>8359431.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>8359431.0</td>\n",
       "      <td>`NEWLINE_TOKENNEWLINE_TOKEN::You are not worth...</td>\n",
       "      <td>2004</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>blocked</td>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1348</th>\n",
       "      <td>8845700.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8845700.0</td>\n",
       "      <td>NEWLINE_TOKENNEWLINE_TOKENi am using the sandb...</td>\n",
       "      <td>2004</td>\n",
       "      <td>False</td>\n",
       "      <td>user</td>\n",
       "      <td>blocked</td>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1521</th>\n",
       "      <td>9664203.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>9664203.0</td>\n",
       "      <td>NEWLINE_TOKENNEWLINE_TOKEN== whoa ==NEWLINE_TO...</td>\n",
       "      <td>2005</td>\n",
       "      <td>False</td>\n",
       "      <td>user</td>\n",
       "      <td>blocked</td>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1527</th>\n",
       "      <td>9679297.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9679297.0</td>\n",
       "      <td>NEWLINE_TOKENNEWLINE_TOKEN== FUCK YOU THUE ==N...</td>\n",
       "      <td>2005</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>blocked</td>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1627</th>\n",
       "      <td>10144987.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>10144987.0</td>\n",
       "      <td>NEWLINE_TOKENNEWLINE_TOKEN:: First of all, who...</td>\n",
       "      <td>2005</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>blocked</td>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1649</th>\n",
       "      <td>10255042.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>10255042.0</td>\n",
       "      <td>Wait a minute.  I looked at your background an...</td>\n",
       "      <td>2005</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>blocked</td>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985</th>\n",
       "      <td>11720728.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>11720728.0</td>\n",
       "      <td>`NEWLINE_TOKENNEWLINE_TOKEN== Personal attacks...</td>\n",
       "      <td>2005</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>blocked</td>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2173</th>\n",
       "      <td>12566441.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>12566441.0</td>\n",
       "      <td>NEWLINE_TOKENNEWLINE_TOKENbtw there needs to b...</td>\n",
       "      <td>2005</td>\n",
       "      <td>False</td>\n",
       "      <td>article</td>\n",
       "      <td>blocked</td>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2233</th>\n",
       "      <td>12807839.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>12807839.0</td>\n",
       "      <td>NEWLINE_TOKENNEWLINE_TOKENHey Ran, don't be so...</td>\n",
       "      <td>2005</td>\n",
       "      <td>False</td>\n",
       "      <td>user</td>\n",
       "      <td>blocked</td>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2334</th>\n",
       "      <td>13247734.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13247734.0</td>\n",
       "      <td>NEWLINE_TOKENNEWLINE_TOKEN== liar ==NEWLINE_TO...</td>\n",
       "      <td>2005</td>\n",
       "      <td>False</td>\n",
       "      <td>article</td>\n",
       "      <td>blocked</td>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2480</th>\n",
       "      <td>13933538.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>13933538.0</td>\n",
       "      <td>NEWLINE_TOKENNEWLINE_TOKENNot after, smartass....</td>\n",
       "      <td>2005</td>\n",
       "      <td>False</td>\n",
       "      <td>article</td>\n",
       "      <td>blocked</td>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499</th>\n",
       "      <td>14001817.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>14001817.0</td>\n",
       "      <td>NEWLINE_TOKENNEWLINE_TOKENNEWLINE_TOKEN== What...</td>\n",
       "      <td>2005</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2564</th>\n",
       "      <td>14331005.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14331005.0</td>\n",
       "      <td>NEWLINE_TOKEN Survey says, chanting fox is idi...</td>\n",
       "      <td>2005</td>\n",
       "      <td>False</td>\n",
       "      <td>user</td>\n",
       "      <td>blocked</td>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2644</th>\n",
       "      <td>14769182.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>14769182.0</td>\n",
       "      <td>`NEWLINE_TOKENNEWLINE_TOKENNEWLINE_TOKENhahah ...</td>\n",
       "      <td>2005</td>\n",
       "      <td>False</td>\n",
       "      <td>article</td>\n",
       "      <td>blocked</td>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2745</th>\n",
       "      <td>15267642.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>15267642.0</td>\n",
       "      <td>NEWLINE_TOKENYour a prick. keep your personal ...</td>\n",
       "      <td>2005</td>\n",
       "      <td>False</td>\n",
       "      <td>user</td>\n",
       "      <td>blocked</td>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2795</th>\n",
       "      <td>15420680.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>15420680.0</td>\n",
       "      <td>NEWLINE_TOKENNEWLINE_TOKENyeah at least i'm no...</td>\n",
       "      <td>2005</td>\n",
       "      <td>False</td>\n",
       "      <td>user</td>\n",
       "      <td>blocked</td>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3158</th>\n",
       "      <td>17149898.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17149898.0</td>\n",
       "      <td>You are a racist pig, loser.  Don't vandalize ...</td>\n",
       "      <td>2005</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>blocked</td>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3293</th>\n",
       "      <td>17719058.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>17719058.0</td>\n",
       "      <td>NEWLINE_TOKENNEWLINE_TOKENhow about you only u...</td>\n",
       "      <td>2005</td>\n",
       "      <td>False</td>\n",
       "      <td>user</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3367</th>\n",
       "      <td>18006573.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>18006573.0</td>\n",
       "      <td>NEWLINE_TOKENYou are a coward and a fool. NEWL...</td>\n",
       "      <td>2005</td>\n",
       "      <td>False</td>\n",
       "      <td>user</td>\n",
       "      <td>blocked</td>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3374</th>\n",
       "      <td>18021080.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18021080.0</td>\n",
       "      <td>NEWLINE_TOKENNEWLINE_TOKEN== idiocy ==NEWLINE_...</td>\n",
       "      <td>2005</td>\n",
       "      <td>False</td>\n",
       "      <td>user</td>\n",
       "      <td>blocked</td>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3391</th>\n",
       "      <td>18081029.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>18081029.0</td>\n",
       "      <td>NEWLINE_TOKENNEWLINE_TOKEN== Omer Fa (Fuck ya)...</td>\n",
       "      <td>2005</td>\n",
       "      <td>False</td>\n",
       "      <td>user</td>\n",
       "      <td>blocked</td>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3399</th>\n",
       "      <td>18101955.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18101955.0</td>\n",
       "      <td>NEWLINE_TOKENNEWLINE_TOKENShut up you faggot. ...</td>\n",
       "      <td>2005</td>\n",
       "      <td>False</td>\n",
       "      <td>user</td>\n",
       "      <td>blocked</td>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3400</th>\n",
       "      <td>18102325.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18102325.0</td>\n",
       "      <td>NEWLINE_TOKENNEWLINE_TOKENShut up. I can do wh...</td>\n",
       "      <td>2005</td>\n",
       "      <td>False</td>\n",
       "      <td>user</td>\n",
       "      <td>blocked</td>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3531</th>\n",
       "      <td>18536206.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18536206.0</td>\n",
       "      <td>NEWLINE_TOKENNEWLINE_TOKEN== Excuse me, whoeve...</td>\n",
       "      <td>2005</td>\n",
       "      <td>False</td>\n",
       "      <td>user</td>\n",
       "      <td>blocked</td>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3591</th>\n",
       "      <td>18674888.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>18674888.0</td>\n",
       "      <td>`NEWLINE_TOKENmaybe you could try and get your...</td>\n",
       "      <td>2005</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>blocked</td>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3692</th>\n",
       "      <td>18840630.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18840630.0</td>\n",
       "      <td>NEWLINE_TOKENit's unfortunate that your mother...</td>\n",
       "      <td>2005</td>\n",
       "      <td>False</td>\n",
       "      <td>user</td>\n",
       "      <td>blocked</td>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3703</th>\n",
       "      <td>18852415.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18852415.0</td>\n",
       "      <td>You ignoramus! My cousin just did the hitler p...</td>\n",
       "      <td>2005</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>blocked</td>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3750</th>\n",
       "      <td>18946187.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>18946187.0</td>\n",
       "      <td>`NEWLINE_TOKENNEWLINE_TOKEN::hehe, you *ARE* t...</td>\n",
       "      <td>2005</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>blocked</td>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156742</th>\n",
       "      <td>680351942.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>680351942.0</td>\n",
       "      <td>NEWLINE_TOKENNEWLINE_TOKENFuck off back to Ind...</td>\n",
       "      <td>2015</td>\n",
       "      <td>False</td>\n",
       "      <td>user</td>\n",
       "      <td>blocked</td>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156754</th>\n",
       "      <td>680482390.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>680482390.0</td>\n",
       "      <td>LOL - you people are absolutely insane.   NEWL...</td>\n",
       "      <td>2015</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>blocked</td>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157041</th>\n",
       "      <td>682431277.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>682431277.0</td>\n",
       "      <td>NEWLINE_TOKENNEWLINE_TOKEN== Terry Hurlock ==N...</td>\n",
       "      <td>2015</td>\n",
       "      <td>False</td>\n",
       "      <td>user</td>\n",
       "      <td>blocked</td>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157205</th>\n",
       "      <td>683847155.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>683847155.0</td>\n",
       "      <td>NEWLINE_TOKENNEWLINE_TOKEN==Stop your bullying...</td>\n",
       "      <td>2015</td>\n",
       "      <td>False</td>\n",
       "      <td>user</td>\n",
       "      <td>blocked</td>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157252</th>\n",
       "      <td>684176068.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>684176068.0</td>\n",
       "      <td>NEWLINE_TOKENNEWLINE_TOKEN== You leave my frie...</td>\n",
       "      <td>2015</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>blocked</td>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157285</th>\n",
       "      <td>684438010.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>684438010.0</td>\n",
       "      <td>NEWLINE_TOKENNEWLINE_TOKEN== do you know what ...</td>\n",
       "      <td>2015</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>blocked</td>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157333</th>\n",
       "      <td>684746726.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>684746726.0</td>\n",
       "      <td>NEWLINE_TOKENNEWLINE_TOKEN== You fascit Nazi! ...</td>\n",
       "      <td>2015</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>blocked</td>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157381</th>\n",
       "      <td>684941825.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>684941825.0</td>\n",
       "      <td>Yamaguchi is a fake &amp; paid PR of lakshmi manch...</td>\n",
       "      <td>2015</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>blocked</td>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157509</th>\n",
       "      <td>685763076.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>685763076.0</td>\n",
       "      <td>NEWLINE_TOKENNEWLINE_TOKENNEWLINE_TOKEN hey as...</td>\n",
       "      <td>2015</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>blocked</td>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157579</th>\n",
       "      <td>686184910.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>686184910.0</td>\n",
       "      <td>NEWLINE_TOKENNEWLINE_TOKEN== FC Bayern Roster ...</td>\n",
       "      <td>2015</td>\n",
       "      <td>False</td>\n",
       "      <td>user</td>\n",
       "      <td>blocked</td>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157903</th>\n",
       "      <td>688520030.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>688520030.0</td>\n",
       "      <td>NEWLINE_TOKENNEWLINE_TOKENI'll fuck you forever!</td>\n",
       "      <td>2015</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>blocked</td>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157905</th>\n",
       "      <td>688523372.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>688523372.0</td>\n",
       "      <td>NEWLINE_TOKENNEWLINE_TOKENFuck you!!!You are a...</td>\n",
       "      <td>2015</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>blocked</td>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157919</th>\n",
       "      <td>688647516.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>688647516.0</td>\n",
       "      <td>Get a sense of humor, you mentally-stuptarded ...</td>\n",
       "      <td>2015</td>\n",
       "      <td>False</td>\n",
       "      <td>user</td>\n",
       "      <td>blocked</td>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157949</th>\n",
       "      <td>688977036.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>688977036.0</td>\n",
       "      <td>NEWLINE_TOKENgo fuck your self asshole</td>\n",
       "      <td>2015</td>\n",
       "      <td>False</td>\n",
       "      <td>user</td>\n",
       "      <td>blocked</td>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158206</th>\n",
       "      <td>690839631.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>690839631.0</td>\n",
       "      <td>November 2015 (UTC)NEWLINE_TOKEN:::Fuck off. ...</td>\n",
       "      <td>2015</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>blocked</td>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158213</th>\n",
       "      <td>690845188.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>690845188.0</td>\n",
       "      <td>Friday 13th: Paris: 129: DEAD. Thank fucking ...</td>\n",
       "      <td>2015</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>blocked</td>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158214</th>\n",
       "      <td>690846056.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>690846056.0</td>\n",
       "      <td>`NEWLINE_TOKENNEWLINE_TOKEN== Fuck you Roger =...</td>\n",
       "      <td>2015</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>blocked</td>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158436</th>\n",
       "      <td>692381139.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>692381139.0</td>\n",
       "      <td>NEWLINE_TOKENNEWLINE_TOKEN== how did this dick...</td>\n",
       "      <td>2015</td>\n",
       "      <td>False</td>\n",
       "      <td>user</td>\n",
       "      <td>blocked</td>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158537</th>\n",
       "      <td>692966052.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>692966052.0</td>\n",
       "      <td>`NEWLINE_TOKENNEWLINE_TOKEN== Q 10: Is it okay...</td>\n",
       "      <td>2015</td>\n",
       "      <td>False</td>\n",
       "      <td>article</td>\n",
       "      <td>blocked</td>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158671</th>\n",
       "      <td>693892979.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>693892979.0</td>\n",
       "      <td>NEWLINE_TOKEN::::::::::You are both liars and ...</td>\n",
       "      <td>2015</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>blocked</td>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158706</th>\n",
       "      <td>694064461.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>694064461.0</td>\n",
       "      <td>NEWLINE_TOKENNEWLINE_TOKEN== Have you actually...</td>\n",
       "      <td>2015</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>blocked</td>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158766</th>\n",
       "      <td>694363419.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>694363419.0</td>\n",
       "      <td>NEWLINE_TOKENNEWLINE_TOKEN==Hey==NEWLINE_TOKEN...</td>\n",
       "      <td>2015</td>\n",
       "      <td>False</td>\n",
       "      <td>user</td>\n",
       "      <td>blocked</td>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158899</th>\n",
       "      <td>695325785.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>695325785.0</td>\n",
       "      <td>U  dam stupid son of a  why u want trouble wij...</td>\n",
       "      <td>2015</td>\n",
       "      <td>False</td>\n",
       "      <td>user</td>\n",
       "      <td>blocked</td>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158926</th>\n",
       "      <td>695442619.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>695442619.0</td>\n",
       "      <td>]] is a dumbfuck racist Undertale fan.</td>\n",
       "      <td>2015</td>\n",
       "      <td>False</td>\n",
       "      <td>user</td>\n",
       "      <td>blocked</td>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159075</th>\n",
       "      <td>696569337.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>696569337.0</td>\n",
       "      <td>NEWLINE_TOKENNEWLINE_TOKEN== Fuck you, old gee...</td>\n",
       "      <td>2015</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>blocked</td>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159126</th>\n",
       "      <td>696865975.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>696865975.0</td>\n",
       "      <td>NEWLINE_TOKENNEWLINE_TOKEN==== What shit u tal...</td>\n",
       "      <td>2015</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>blocked</td>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159186</th>\n",
       "      <td>697160144.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>697160144.0</td>\n",
       "      <td>NEWLINE_TOKENNEWLINE_TOKEN== Moron ==NEWLINE_T...</td>\n",
       "      <td>2015</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>blocked</td>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159378</th>\n",
       "      <td>698258529.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>698258529.0</td>\n",
       "      <td>NEWLINE_TOKENNEWLINE_TOKENUR Stupid Mate, Bloc...</td>\n",
       "      <td>2016</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>blocked</td>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159445</th>\n",
       "      <td>698712715.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>698712715.0</td>\n",
       "      <td>NEWLINE_TOKENHoly shit, you people suck. I don...</td>\n",
       "      <td>2016</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>blocked</td>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159530</th>\n",
       "      <td>699163319.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>699163319.0</td>\n",
       "      <td>`NEWLINE_TOKENNEWLINE_TOKEN== Go fuck yourself...</td>\n",
       "      <td>2016</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>blocked</td>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2317 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        rev_idrev_id  toxicity  rev_idrev_id  \\\n",
       "829        5815399.0       0.7     5815399.0   \n",
       "1227       8357736.0       0.3     8357736.0   \n",
       "1228       8359431.0       0.5     8359431.0   \n",
       "1348       8845700.0       1.0     8845700.0   \n",
       "1521       9664203.0       0.8     9664203.0   \n",
       "1527       9679297.0       1.0     9679297.0   \n",
       "1627      10144987.0       0.8    10144987.0   \n",
       "1649      10255042.0       0.4    10255042.0   \n",
       "1985      11720728.0       0.6    11720728.0   \n",
       "2173      12566441.0       0.5    12566441.0   \n",
       "2233      12807839.0       0.9    12807839.0   \n",
       "2334      13247734.0       1.0    13247734.0   \n",
       "2480      13933538.0       0.6    13933538.0   \n",
       "2499      14001817.0       0.6    14001817.0   \n",
       "2564      14331005.0       1.0    14331005.0   \n",
       "2644      14769182.0       0.9    14769182.0   \n",
       "2745      15267642.0       0.9    15267642.0   \n",
       "2795      15420680.0       0.9    15420680.0   \n",
       "3158      17149898.0       1.0    17149898.0   \n",
       "3293      17719058.0       0.7    17719058.0   \n",
       "3367      18006573.0       0.9    18006573.0   \n",
       "3374      18021080.0       1.0    18021080.0   \n",
       "3391      18081029.0       0.9    18081029.0   \n",
       "3399      18101955.0       1.0    18101955.0   \n",
       "3400      18102325.0       1.0    18102325.0   \n",
       "3531      18536206.0       1.0    18536206.0   \n",
       "3591      18674888.0       0.8    18674888.0   \n",
       "3692      18840630.0       1.0    18840630.0   \n",
       "3703      18852415.0       1.0    18852415.0   \n",
       "3750      18946187.0       0.8    18946187.0   \n",
       "...              ...       ...           ...   \n",
       "156742   680351942.0       1.0   680351942.0   \n",
       "156754   680482390.0       0.6   680482390.0   \n",
       "157041   682431277.0       0.5   682431277.0   \n",
       "157205   683847155.0       0.7   683847155.0   \n",
       "157252   684176068.0       0.8   684176068.0   \n",
       "157285   684438010.0       1.0   684438010.0   \n",
       "157333   684746726.0       1.0   684746726.0   \n",
       "157381   684941825.0       1.0   684941825.0   \n",
       "157509   685763076.0       1.0   685763076.0   \n",
       "157579   686184910.0       1.0   686184910.0   \n",
       "157903   688520030.0       0.9   688520030.0   \n",
       "157905   688523372.0       1.0   688523372.0   \n",
       "157919   688647516.0       0.9   688647516.0   \n",
       "157949   688977036.0       1.0   688977036.0   \n",
       "158206   690839631.0       0.9   690839631.0   \n",
       "158213   690845188.0       1.0   690845188.0   \n",
       "158214   690846056.0       1.0   690846056.0   \n",
       "158436   692381139.0       1.0   692381139.0   \n",
       "158537   692966052.0       0.8   692966052.0   \n",
       "158671   693892979.0       0.9   693892979.0   \n",
       "158706   694064461.0       0.9   694064461.0   \n",
       "158766   694363419.0       1.0   694363419.0   \n",
       "158899   695325785.0       1.0   695325785.0   \n",
       "158926   695442619.0       1.0   695442619.0   \n",
       "159075   696569337.0       1.0   696569337.0   \n",
       "159126   696865975.0       1.0   696865975.0   \n",
       "159186   697160144.0       0.8   697160144.0   \n",
       "159378   698258529.0       0.9   698258529.0   \n",
       "159445   698712715.0       0.6   698712715.0   \n",
       "159530   699163319.0       1.0   699163319.0   \n",
       "\n",
       "                                                  comment  year  logged_in  \\\n",
       "829     NEWLINE_TOKENNEWLINE_TOKENIt was anonymous on ...  2004       True   \n",
       "1227         NEWLINE_TOKENNEWLINE_TOKENYou are a child.    2004       True   \n",
       "1228    `NEWLINE_TOKENNEWLINE_TOKEN::You are not worth...  2004       True   \n",
       "1348    NEWLINE_TOKENNEWLINE_TOKENi am using the sandb...  2004      False   \n",
       "1521    NEWLINE_TOKENNEWLINE_TOKEN== whoa ==NEWLINE_TO...  2005      False   \n",
       "1527    NEWLINE_TOKENNEWLINE_TOKEN== FUCK YOU THUE ==N...  2005       True   \n",
       "1627    NEWLINE_TOKENNEWLINE_TOKEN:: First of all, who...  2005       True   \n",
       "1649    Wait a minute.  I looked at your background an...  2005       True   \n",
       "1985    `NEWLINE_TOKENNEWLINE_TOKEN== Personal attacks...  2005       True   \n",
       "2173    NEWLINE_TOKENNEWLINE_TOKENbtw there needs to b...  2005      False   \n",
       "2233    NEWLINE_TOKENNEWLINE_TOKENHey Ran, don't be so...  2005      False   \n",
       "2334    NEWLINE_TOKENNEWLINE_TOKEN== liar ==NEWLINE_TO...  2005      False   \n",
       "2480    NEWLINE_TOKENNEWLINE_TOKENNot after, smartass....  2005      False   \n",
       "2499    NEWLINE_TOKENNEWLINE_TOKENNEWLINE_TOKEN== What...  2005       True   \n",
       "2564    NEWLINE_TOKEN Survey says, chanting fox is idi...  2005      False   \n",
       "2644    `NEWLINE_TOKENNEWLINE_TOKENNEWLINE_TOKENhahah ...  2005      False   \n",
       "2745    NEWLINE_TOKENYour a prick. keep your personal ...  2005      False   \n",
       "2795    NEWLINE_TOKENNEWLINE_TOKENyeah at least i'm no...  2005      False   \n",
       "3158    You are a racist pig, loser.  Don't vandalize ...  2005       True   \n",
       "3293    NEWLINE_TOKENNEWLINE_TOKENhow about you only u...  2005      False   \n",
       "3367    NEWLINE_TOKENYou are a coward and a fool. NEWL...  2005      False   \n",
       "3374    NEWLINE_TOKENNEWLINE_TOKEN== idiocy ==NEWLINE_...  2005      False   \n",
       "3391    NEWLINE_TOKENNEWLINE_TOKEN== Omer Fa (Fuck ya)...  2005      False   \n",
       "3399    NEWLINE_TOKENNEWLINE_TOKENShut up you faggot. ...  2005      False   \n",
       "3400    NEWLINE_TOKENNEWLINE_TOKENShut up. I can do wh...  2005      False   \n",
       "3531    NEWLINE_TOKENNEWLINE_TOKEN== Excuse me, whoeve...  2005      False   \n",
       "3591    `NEWLINE_TOKENmaybe you could try and get your...  2005       True   \n",
       "3692    NEWLINE_TOKENit's unfortunate that your mother...  2005      False   \n",
       "3703    You ignoramus! My cousin just did the hitler p...  2005       True   \n",
       "3750    `NEWLINE_TOKENNEWLINE_TOKEN::hehe, you *ARE* t...  2005       True   \n",
       "...                                                   ...   ...        ...   \n",
       "156742  NEWLINE_TOKENNEWLINE_TOKENFuck off back to Ind...  2015      False   \n",
       "156754  LOL - you people are absolutely insane.   NEWL...  2015       True   \n",
       "157041  NEWLINE_TOKENNEWLINE_TOKEN== Terry Hurlock ==N...  2015      False   \n",
       "157205  NEWLINE_TOKENNEWLINE_TOKEN==Stop your bullying...  2015      False   \n",
       "157252  NEWLINE_TOKENNEWLINE_TOKEN== You leave my frie...  2015       True   \n",
       "157285  NEWLINE_TOKENNEWLINE_TOKEN== do you know what ...  2015       True   \n",
       "157333  NEWLINE_TOKENNEWLINE_TOKEN== You fascit Nazi! ...  2015       True   \n",
       "157381  Yamaguchi is a fake & paid PR of lakshmi manch...  2015       True   \n",
       "157509  NEWLINE_TOKENNEWLINE_TOKENNEWLINE_TOKEN hey as...  2015       True   \n",
       "157579  NEWLINE_TOKENNEWLINE_TOKEN== FC Bayern Roster ...  2015      False   \n",
       "157903   NEWLINE_TOKENNEWLINE_TOKENI'll fuck you forever!  2015       True   \n",
       "157905  NEWLINE_TOKENNEWLINE_TOKENFuck you!!!You are a...  2015       True   \n",
       "157919  Get a sense of humor, you mentally-stuptarded ...  2015      False   \n",
       "157949             NEWLINE_TOKENgo fuck your self asshole  2015      False   \n",
       "158206   November 2015 (UTC)NEWLINE_TOKEN:::Fuck off. ...  2015       True   \n",
       "158213   Friday 13th: Paris: 129: DEAD. Thank fucking ...  2015       True   \n",
       "158214  `NEWLINE_TOKENNEWLINE_TOKEN== Fuck you Roger =...  2015       True   \n",
       "158436  NEWLINE_TOKENNEWLINE_TOKEN== how did this dick...  2015      False   \n",
       "158537  `NEWLINE_TOKENNEWLINE_TOKEN== Q 10: Is it okay...  2015      False   \n",
       "158671  NEWLINE_TOKEN::::::::::You are both liars and ...  2015       True   \n",
       "158706  NEWLINE_TOKENNEWLINE_TOKEN== Have you actually...  2015       True   \n",
       "158766  NEWLINE_TOKENNEWLINE_TOKEN==Hey==NEWLINE_TOKEN...  2015      False   \n",
       "158899  U  dam stupid son of a  why u want trouble wij...  2015      False   \n",
       "158926             ]] is a dumbfuck racist Undertale fan.  2015      False   \n",
       "159075  NEWLINE_TOKENNEWLINE_TOKEN== Fuck you, old gee...  2015       True   \n",
       "159126  NEWLINE_TOKENNEWLINE_TOKEN==== What shit u tal...  2015       True   \n",
       "159186  NEWLINE_TOKENNEWLINE_TOKEN== Moron ==NEWLINE_T...  2015       True   \n",
       "159378  NEWLINE_TOKENNEWLINE_TOKENUR Stupid Mate, Bloc...  2016       True   \n",
       "159445  NEWLINE_TOKENHoly shit, you people suck. I don...  2016       True   \n",
       "159530  `NEWLINE_TOKENNEWLINE_TOKEN== Go fuck yourself...  2016       True   \n",
       "\n",
       "             ns   sample split  binary_tox  predicted  \n",
       "829     article   random  test           1          1  \n",
       "1227       user  blocked  test           0          1  \n",
       "1228       user  blocked  test           1          1  \n",
       "1348       user  blocked  test           1          1  \n",
       "1521       user  blocked  test           1          1  \n",
       "1527       user  blocked  test           1          1  \n",
       "1627       user  blocked  test           1          1  \n",
       "1649    article  blocked  test           0          1  \n",
       "1985    article  blocked  test           1          1  \n",
       "2173    article  blocked  test           1          1  \n",
       "2233       user  blocked  test           1          1  \n",
       "2334    article  blocked  test           1          1  \n",
       "2480    article  blocked  test           1          1  \n",
       "2499       user   random  test           1          1  \n",
       "2564       user  blocked  test           1          1  \n",
       "2644    article  blocked  test           1          1  \n",
       "2745       user  blocked  test           1          1  \n",
       "2795       user  blocked  test           1          1  \n",
       "3158       user  blocked  test           1          1  \n",
       "3293       user   random  test           1          1  \n",
       "3367       user  blocked  test           1          1  \n",
       "3374       user  blocked  test           1          1  \n",
       "3391       user  blocked  test           1          1  \n",
       "3399       user  blocked  test           1          1  \n",
       "3400       user  blocked  test           1          1  \n",
       "3531       user  blocked  test           1          1  \n",
       "3591       user  blocked  test           1          1  \n",
       "3692       user  blocked  test           1          1  \n",
       "3703       user  blocked  test           1          1  \n",
       "3750       user  blocked  test           1          1  \n",
       "...         ...      ...   ...         ...        ...  \n",
       "156742     user  blocked  test           1          1  \n",
       "156754     user  blocked  test           1          1  \n",
       "157041     user  blocked  test           1          1  \n",
       "157205     user  blocked  test           1          1  \n",
       "157252     user  blocked  test           1          1  \n",
       "157285     user  blocked  test           1          1  \n",
       "157333     user  blocked  test           1          1  \n",
       "157381     user  blocked  test           1          1  \n",
       "157509     user  blocked  test           1          1  \n",
       "157579     user  blocked  test           1          1  \n",
       "157903     user  blocked  test           1          1  \n",
       "157905     user  blocked  test           1          1  \n",
       "157919     user  blocked  test           1          1  \n",
       "157949     user  blocked  test           1          1  \n",
       "158206  article  blocked  test           1          1  \n",
       "158213     user  blocked  test           1          1  \n",
       "158214     user  blocked  test           1          1  \n",
       "158436     user  blocked  test           1          1  \n",
       "158537  article  blocked  test           1          1  \n",
       "158671  article  blocked  test           1          1  \n",
       "158706     user  blocked  test           1          1  \n",
       "158766     user  blocked  test           1          1  \n",
       "158899     user  blocked  test           1          1  \n",
       "158926     user  blocked  test           1          1  \n",
       "159075     user  blocked  test           1          1  \n",
       "159126     user  blocked  test           1          1  \n",
       "159186     user  blocked  test           1          1  \n",
       "159378     user  blocked  test           1          1  \n",
       "159445     user  blocked  test           1          1  \n",
       "159530     user  blocked  test           1          1  \n",
       "\n",
       "[2317 rows x 11 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_comments[test_comments['predicted'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(['Thanks for you contribution, you did a great job!'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(['People as stupid as you should not edit Wikipedia!'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(['I am a proud gay'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# test_comm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_comm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_TERMS = ['tall', 'wikipedia', 'teacher', 'music', 'box',\n",
    "              'lesbian', 'gay', 'bisexual', 'transgender', 'queer',\n",
    "              'homosexual', 'heterosexual', 'straight',\n",
    "              'muslim', 'jewish', 'jew', 'christian',\n",
    "              'feminist', 'black', 'white']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# true_label = []\n",
    "# temp_true = 0\n",
    "# for i in TEST_TERMS:\n",
    "#     for row in joined_tox:\n",
    "#         if i in row['comment'] and binary_tox == 1:\n",
    "#             temp_true += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "madlibs_terms = model_bias_analysis.read_identity_terms('adjectives_people.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = model_bias_analysis.per_subgroup_negative_rates(joined_tox, madlibs_terms, )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
