{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Much of this code was lifted from [the Conversation AI project](https://conversationai.github.io/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import model_bias_analysis\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read TSVs from file. These are the original data from *Conversation AI*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD_BINARY_TOXICITY = 0.5\n",
    "\n",
    "def read_files():\n",
    "    comments = pd.read_csv(\"toxicity_annotated_comments.tsv\"\\\n",
    "                                          , sep = \"\\t\")\n",
    "    annotations = pd.read_csv(\"toxicity_annotations.tsv\"\\\n",
    "                                          , sep = \"\\t\")\n",
    "    # toxicity_worker_demographics = pd.read_csv(\"toxicity_worker_demographics.tsv\"\\\n",
    "#                                           , sep = \"\\t\")\n",
    "    grouped_annotations = annotations.groupby('rev_id',as_index=False)['toxicity'].mean()\n",
    "    joined_tox = grouped_annotations.join(comments, lsuffix='rev_id', rsuffix='rev_id', how='left', sort=True) \n",
    "    joined_tox['binary_tox'] = np.where(joined_tox['toxicity']>=THRESHOLD_BINARY_TOXICITY, 1, 0)\n",
    "    \n",
    "    # remove newline and tab tokens\n",
    "    joined_tox['comment'] = joined_tox.comment.apply(lambda x: x.replace('NEWLINE_TOKEN', '').replace('TAB_TOKEN', ''))\n",
    "    joined_tox['len_comment'] = joined_tox.comment.apply(lambda x: len(x))\n",
    "    \n",
    "    return joined_tox\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_test_train(joined_tox):\n",
    "    test_comments = joined_tox.query(\"split == 'test' \")\n",
    "    train_comments = joined_tox.query(\"split == 'train' \")\n",
    "    \n",
    "    return test_comments, train_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_identity_terms(test_comments, train_comments):\n",
    "\n",
    "    # Currently not in use, but possibly we'll switch to use this later\n",
    "\n",
    "    # TEST_TERMS = ['tall', 'wikipedia', 'teacher', 'music', 'box',\n",
    "    #               'lesbian', 'gay', 'bisexual', 'transgender', 'queer',\n",
    "    #               'homosexual', 'heterosexual', 'straight',\n",
    "    #               'muslim', 'jewish', 'jew', 'christian',\n",
    "    #               'feminist', 'black', 'white']\n",
    "\n",
    "    madlibs_terms = model_bias_analysis.read_identity_terms('adjectives_people.txt')\n",
    "\n",
    "    # Add identity labels to train and test comments\n",
    "    model_bias_analysis.add_subgroup_columns_from_text(train_comments, 'comment', madlibs_terms)\n",
    "    model_bias_analysis.add_subgroup_columns_from_text(test_comments, 'comment', madlibs_terms)\n",
    "    \n",
    "    return madlibs_terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* *grouped_annotations* takes the mean of all toxicity ratings of a comment.\n",
    "* *joined_tox* joins *grouped_annotations* and *comments*.\n",
    "* We also add a column *binary_tox* to the dataframe *joined_tox*. Here we assign a toxicity rating of 0 or 1 based on whether the mean toxicity rating is above or below 0.5 (or other value determined by threshold_binary_toxicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joined_tox = read_files()\n",
    "# test_comments, train_comments = split_test_train(joined_tox)\n",
    "# madlibs_terms = add_identity_terms(test_comments, train_comments)\n",
    "\n",
    "# This writes the 3 dataframes to csv so that we can read from that later for shorter code.\n",
    "# joined_tox.to_csv('joined_tox.csv')\n",
    "# train_comments.to_csv('train_comments.csv')\n",
    "# test_comments.to_csv('test_comments.csv')\n",
    "\n",
    "# Either use this or the commented-out stuff above. That (above) reads all of the actual files and generates df's\n",
    "# This (below) reads pre-generated df's so that we don't have to run all the 3 functions above each time. \n",
    "\n",
    "joined_tox = pd.read_csv('joined_tox.csv')\n",
    "train_comments = pd.read_csv('train_comments.csv')\n",
    "test_comments = pd.read_csv('test_comments.csv')\n",
    "madlibs_terms = model_bias_analysis.read_identity_terms('adjectives_people.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data cleaning needed:\n",
    "# What identity terms are we taking out and why? Brandons' initial suggestion was in less than 5% of toxic comments\n",
    "# But we might have to do less than 5% of toxic comments WITH an identity term\n",
    "# I also think it's really important to balance by comment length...but how?\n",
    "\n",
    "# Another thing to check for data cleaning. Are we using the test set determined in the paper?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train logistic regression classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Equation DI:\n",
    "DI(t1,t2) = (probability that comment containing term t1 is labeled toxic) / (probability that comment containing term t2 is labelled toxic)\n",
    "= a/b\n",
    "\n",
    "a = # comments containing t1 AND toxic / # comments containing t1\n",
    "= alpha/beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confirm that you can find alpha\n",
    "train_comments[train_comments['lesbian'] == True].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confirm that you can find beta\n",
    "train_comments[(train_comments['lesbian'] == True) & (train_comments['binary_tox'] == 1)].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>rev_idrev_id</th>\n",
       "      <th>toxicity</th>\n",
       "      <th>rev_idrev_id.1</th>\n",
       "      <th>comment</th>\n",
       "      <th>year</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>ns</th>\n",
       "      <th>sample</th>\n",
       "      <th>split</th>\n",
       "      <th>...</th>\n",
       "      <th>older</th>\n",
       "      <th>young</th>\n",
       "      <th>younger</th>\n",
       "      <th>teenage</th>\n",
       "      <th>millenial</th>\n",
       "      <th>middle aged</th>\n",
       "      <th>elderly</th>\n",
       "      <th>blind</th>\n",
       "      <th>deaf</th>\n",
       "      <th>paralyzed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2232.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2232.0</td>\n",
       "      <td>This:NEWLINE_TOKEN:One can make an analogy in ...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4216.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4216.0</td>\n",
       "      <td>`NEWLINE_TOKENNEWLINE_TOKEN:Clarification for ...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>26547.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26547.0</td>\n",
       "      <td>`This is such a fun entry.   DevotchkaNEWLINE_...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>37330.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>37330.0</td>\n",
       "      <td>`NEWLINE_TOKENNEWLINE_TOKENNEWLINE_TOKENI fixe...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>37346.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>37346.0</td>\n",
       "      <td>`If they are ``indisputable`` then why does th...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  rev_idrev_id  toxicity  rev_idrev_id.1  \\\n",
       "0           0        2232.0       0.1          2232.0   \n",
       "1           1        4216.0       0.0          4216.0   \n",
       "2           3       26547.0       0.0         26547.0   \n",
       "3           6       37330.0       0.3         37330.0   \n",
       "4           7       37346.0       0.1         37346.0   \n",
       "\n",
       "                                             comment  year  logged_in  \\\n",
       "0  This:NEWLINE_TOKEN:One can make an analogy in ...  2002       True   \n",
       "1  `NEWLINE_TOKENNEWLINE_TOKEN:Clarification for ...  2002       True   \n",
       "2  `This is such a fun entry.   DevotchkaNEWLINE_...  2002       True   \n",
       "3  `NEWLINE_TOKENNEWLINE_TOKENNEWLINE_TOKENI fixe...  2002       True   \n",
       "4  `If they are ``indisputable`` then why does th...  2002       True   \n",
       "\n",
       "        ns  sample  split    ...      older  young  younger  teenage  \\\n",
       "0  article  random  train    ...      False  False    False    False   \n",
       "1     user  random  train    ...      False  False    False    False   \n",
       "2  article  random  train    ...      False  False    False    False   \n",
       "3  article  random  train    ...      False  False    False    False   \n",
       "4  article  random  train    ...      False  False    False    False   \n",
       "\n",
       "   millenial  middle aged  elderly  blind   deaf  paralyzed  \n",
       "0      False        False    False  False  False      False  \n",
       "1      False        False    False  False  False      False  \n",
       "2      False        False    False  False  False      False  \n",
       "3      False        False    False  False  False      False  \n",
       "4      False        False    False  False  False      False  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_comments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.39473684  0.62544803  0.07692308  0.26315789  0.0952381   0.74509804\n",
      "  0.07017544  1.          0.46774194  0.13702624  0.15789474  0.17073171\n",
      "  0.15577889 -1.          0.08474576  0.16326531  0.18042813  0.15853659\n",
      "  0.09090909  0.10416667  0.11111111  0.2        -1.          0.2739726\n",
      "  0.06944444  0.09857978  0.12        0.11444142  0.09090909  0.12058824\n",
      "  0.07216495  0.09190372  0.13057325  0.11860465  0.02173913  0.08906883\n",
      "  0.03846154  0.11111111 -1.          0.12916667  0.0472103   0.09433962\n",
      "  0.03529412  0.125       0.         -1.          0.          0.19496855\n",
      "  0.08       -1.        ]\n"
     ]
    }
   ],
   "source": [
    "def calculate_pairwise_di(df, madlibs_terms, colname):\n",
    "    \n",
    "    # We now calculate the DI for each pair for the training data.\n",
    "\n",
    "    term_toxicity = np.zeros(len(madlibs_terms))\n",
    "\n",
    "    # we temporarily put -1 in as a placeholder for stuff that has no exacmples of terms with that term.\n",
    "    # non-binary is one\n",
    "    for i in range(len(madlibs_terms)):\n",
    "        try:\n",
    "            term_toxicity[i] = float((df[(df[madlibs_terms[i]] == True) & (df[colname] == 1)].shape[0]))/  \\\n",
    "            float((df[df[madlibs_terms[i]] == True].shape[0]))\n",
    "        except ZeroDivisionError:\n",
    "            term_toxicity[i] = -1 \n",
    "\n",
    "    return term_toxicity\n",
    "\n",
    "term_toxicity = calculate_pairwise_di(train_comments, madlibs_terms, 'binary_tox')\n",
    "print(term_toxicity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46.0 (7, 34)\n",
      "lgbtq buddhist\n"
     ]
    }
   ],
   "source": [
    "# This finds the max DI between all pairs of identity terms, which for one of our experiments,\n",
    "# we're claiming is kind of the DI of all terms\n",
    "# Possibly something we'll take out or come back to once we try more versions of our code. (Neha's working on this!)\n",
    "\n",
    "def find_max_di(term_toxicity, madlibs_terms):\n",
    "    # General questions for potential problems with this method:\n",
    "    # Do we want the 0s? That would mean they are never used in a toxic way but can't divide by 0...\n",
    "    # Also, how often do terms appear? Is sample size crazy small right now?? \n",
    "    max_prop = 0\n",
    "    top_indexes = ()\n",
    "\n",
    "    for i in range(len(madlibs_terms)):\n",
    "        for j in range(len(madlibs_terms)):\n",
    "            if (i==j or term_toxicity[i] == -1 or term_toxicity[j] == -1 or term_toxicity[j] == 0):\n",
    "                continue\n",
    "            if term_toxicity[i]/ term_toxicity[j] > max_prop:\n",
    "                max_prop = term_toxicity[i]/ term_toxicity[j]\n",
    "                top_indexes = (i,j)\n",
    "                \n",
    "    return max_prop, top_indexes\n",
    "\n",
    "max_prop, top_indexes = find_max_di(term_toxicity, madlibs_terms)\n",
    "\n",
    "print(max_prop, top_indexes)\n",
    "print(madlibs_terms[7], madlibs_terms[34])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now! We do the same thing but for the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# alpha of test\n",
    "test_comments[test_comments['lesbian'] == True].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# beta of test\n",
    "test_comments[(test_comments['lesbian'] == True) & (test_comments['predicted'] == 1)].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generates perturbations\n",
    "# Basically, creates num_perturbations number of arrays. \n",
    "# Each array is the length of the train_comments\n",
    "# Each item in the array is 0/1 and is PROBABILITY_FLIP flipped from the true value of binary toxicity \n",
    "\n",
    "PROBABILITY_FLIP = 0.5\n",
    "def generate_perturbation_on_training(train_comments, num_perturbations):\n",
    "    \n",
    "    list_perturbation = []\n",
    "\n",
    "    length = len(train_comments.binary_tox.values)\n",
    "    for j in range(num_perturbations):\n",
    "        rand = np.random.random(length) # generate a random number (between 0 and 1) for each comment\n",
    "        tox_tmp = np.copy(train_comments.binary_tox.values) # np.copy(tox_np)\n",
    "        for i in range(length):\n",
    "            if rand[i] >= PROBABILITY_FLIP: # if random number is greater than 0.5, replace value in array with a random integer from [0, 1]\n",
    "                tox_tmp[i] = np.random.randint(2)\n",
    "        list_perturbation.append(tox_tmp)\n",
    "\n",
    "    # each item in list_perturbation is a list of 0s and 1s that correspond to the new binary_tox of each variable\n",
    "    \n",
    "    return list_perturbation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0, 0, 1, ..., 0, 0, 1], dtype=int64), array([0, 0, 1, ..., 0, 0, 0], dtype=int64), array([1, 0, 0, ..., 0, 0, 0], dtype=int64), array([0, 1, 0, ..., 0, 0, 0], dtype=int64), array([1, 0, 1, ..., 1, 0, 0], dtype=int64), array([0, 1, 0, ..., 1, 0, 0], dtype=int64), array([1, 0, 1, ..., 1, 0, 0], dtype=int64), array([0, 1, 0, ..., 0, 1, 1], dtype=int64), array([1, 1, 0, ..., 0, 0, 0], dtype=int64), array([0, 0, 0, ..., 0, 0, 0], dtype=int64)]\n"
     ]
    }
   ],
   "source": [
    "NUM_PERTURBATIONS = 10\n",
    "list_perturbations_training = generate_perturbation_on_training(train_comments, NUM_PERTURBATIONS)\n",
    "print(list_perturbations_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate max DIs on all of the perturbed training datasets\n",
    "def find_max_dis_of_perturbations(df_comments, list_perturbation, madlibs_terms):\n",
    "    \n",
    "    array_dis = []\n",
    "\n",
    "    for i in range(NUM_PERTURBATIONS):\n",
    "        df_comments['newcol'] = list_perturbation[i]\n",
    "        term_toxicity = calculate_pairwise_di(df_comments, madlibs_terms, 'newcol')\n",
    "        max_prop, top_indexes = find_max_di(term_toxicity, madlibs_terms)\n",
    "        array_dis.append((max_prop, top_indexes))\n",
    "        \n",
    "    return array_dis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** [(11.0, (7, 46)), (5.75, (7, 34)), (4.341696535244923, (1, 34)), (6.071428571428571, (7, 42)), (9.0, (7, 20)), (8.666666666666666, (7, 2)), (4.236363636363636, (7, 40)), (11.0, (7, 46)), (5.5, (7, 46)), (6.5, (7, 2))]\n"
     ]
    }
   ],
   "source": [
    "training_data_dis = find_max_dis_of_perturbations(train_comments, list_perturbations_training, madlibs_terms)\n",
    "print(\"**\", training_data_dis)\n",
    "# This is the array of all of the max_dis, and the indexes of the madlibs_terms array that composed that max_di"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_predict(train_comments, list_perturbations_training, test_comments):\n",
    "\n",
    "    # This trains a classifier on n different perturbed datsets\n",
    "    d={}\n",
    "    for x in range(NUM_PERTURBATIONS):\n",
    "        d[\"clf{0}\".format(x)] = Pipeline([\n",
    "            ('vect', CountVectorizer(max_features = 10000, ngram_range = (1,2))),\n",
    "            ('tfidf', TfidfTransformer(norm = 'l2')),\n",
    "            ('clf', LogisticRegression()),\n",
    "        ])\n",
    "        d[\"clf{0}\".format(x)] = d[\"clf{0}\".format(x)].\\\n",
    "                                    fit(train_comments['comment'], list_perturbations_training[x])\n",
    "        d[\"auc{0}\".format(x)] = roc_auc_score(test_comments['binary_tox'], \\\n",
    "                                    d[\"clf{0}\".format(x)].predict_proba(test_comments['comment'])[:, 1])\n",
    "        print('Test ROC AUC: %.5f' %d[\"auc{0}\".format(x)])\n",
    "        \n",
    "    # Once a classifier is trained, this goes to the test data and creates predictions on test data\n",
    "    perturbed_predictions = [] # list, each item is array of predictions. element 0 is 0th perturbation and \n",
    "    # predictions based on that.\n",
    "    # each item in the array is a column that indicates 0/1 for predicted not-toxic/toxic\n",
    "\n",
    "    for i in range(NUM_PERTURBATIONS):\n",
    "        perturbed_predictions.append(d[\"clf{0}\".format(i)].predict(test_comments['comment']))\n",
    "                                                                                 \n",
    "    return perturbed_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caution, that cell below takes a really long time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test ROC AUC: 0.88783\n",
      "Test ROC AUC: 0.88791\n",
      "Test ROC AUC: 0.88290\n",
      "Test ROC AUC: 0.89198\n",
      "Test ROC AUC: 0.88307\n",
      "Test ROC AUC: 0.88822\n",
      "Test ROC AUC: 0.88823\n",
      "Test ROC AUC: 0.88520\n",
      "Test ROC AUC: 0.88630\n",
      "Test ROC AUC: 0.88459\n",
      "[array([0, 0, 0, ..., 0, 0, 0], dtype=int64), array([0, 0, 0, ..., 0, 0, 0], dtype=int64), array([0, 0, 0, ..., 0, 0, 0], dtype=int64), array([0, 0, 0, ..., 0, 0, 0], dtype=int64), array([0, 0, 0, ..., 0, 0, 0], dtype=int64), array([0, 0, 0, ..., 0, 0, 0], dtype=int64), array([0, 0, 0, ..., 0, 0, 0], dtype=int64), array([0, 1, 0, ..., 0, 0, 0], dtype=int64), array([0, 0, 0, ..., 0, 0, 0], dtype=int64), array([0, 0, 0, ..., 0, 0, 0], dtype=int64)]\n"
     ]
    }
   ],
   "source": [
    "perturbed_predictions = train_and_predict(train_comments, list_perturbations_training, test_comments)\n",
    "print(perturbed_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28249  3617]\n",
      "[29391  2475]\n",
      "[29461  2405]\n",
      "[29410  2456]\n",
      "[29374  2492]\n",
      "[29498  2368]\n",
      "[29400  2466]\n",
      "[29391  2475]\n",
      "[29376  2490]\n",
      "[29454  2412]\n",
      "[29494  2372]\n"
     ]
    }
   ],
   "source": [
    "# Sanity check\n",
    "print(np.bincount(test_comments.binary_tox.values))\n",
    "# More sanity\n",
    "for arr in perturbed_predictions:\n",
    "    print(np.bincount(arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_comments['newcol'] = perturbed_predictions[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>rev_idrev_id</th>\n",
       "      <th>toxicity</th>\n",
       "      <th>rev_idrev_id.1</th>\n",
       "      <th>comment</th>\n",
       "      <th>year</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>ns</th>\n",
       "      <th>sample</th>\n",
       "      <th>split</th>\n",
       "      <th>...</th>\n",
       "      <th>young</th>\n",
       "      <th>younger</th>\n",
       "      <th>teenage</th>\n",
       "      <th>millenial</th>\n",
       "      <th>middle aged</th>\n",
       "      <th>elderly</th>\n",
       "      <th>blind</th>\n",
       "      <th>deaf</th>\n",
       "      <th>paralyzed</th>\n",
       "      <th>newcol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>8953.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8953.0</td>\n",
       "      <td>Elected or Electoral? JHK</td>\n",
       "      <td>2002</td>\n",
       "      <td>False</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>28959.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>28959.0</td>\n",
       "      <td>Please relate the ozone hole to increases in c...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19</td>\n",
       "      <td>138074.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>138074.0</td>\n",
       "      <td>`NEWLINE_TOKENNEWLINE_TOKENNEWLINE_TOKENNEWLIN...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>200664.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200664.0</td>\n",
       "      <td>NEWLINE_TOKENNEWLINE_TOKENNEWLINE_TOKEN NEWLIN...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37</td>\n",
       "      <td>213105.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>213105.0</td>\n",
       "      <td>`NEWLINE_TOKENNEWLINE_TOKEN: I should do that ...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  rev_idrev_id  toxicity  rev_idrev_id.1  \\\n",
       "0           2        8953.0       0.0          8953.0   \n",
       "1           4       28959.0       0.2         28959.0   \n",
       "2          19      138074.0       0.0        138074.0   \n",
       "3          33      200664.0       0.0        200664.0   \n",
       "4          37      213105.0       0.0        213105.0   \n",
       "\n",
       "                                             comment  year  logged_in  \\\n",
       "0                          Elected or Electoral? JHK  2002      False   \n",
       "1  Please relate the ozone hole to increases in c...  2002       True   \n",
       "2  `NEWLINE_TOKENNEWLINE_TOKENNEWLINE_TOKENNEWLIN...  2002       True   \n",
       "3  NEWLINE_TOKENNEWLINE_TOKENNEWLINE_TOKEN NEWLIN...  2002       True   \n",
       "4  `NEWLINE_TOKENNEWLINE_TOKEN: I should do that ...  2002       True   \n",
       "\n",
       "        ns  sample split   ...    young  younger  teenage  millenial  \\\n",
       "0  article  random  test   ...    False    False    False      False   \n",
       "1  article  random  test   ...    False    False    False      False   \n",
       "2  article  random  test   ...    False    False    False      False   \n",
       "3     user  random  test   ...    False    False    False      False   \n",
       "4     user  random  test   ...    False    False    False      False   \n",
       "\n",
       "   middle aged  elderly  blind   deaf  paralyzed  newcol  \n",
       "0        False    False  False  False      False       0  \n",
       "1        False    False  False  False      False       0  \n",
       "2        False    False  False  False      False       0  \n",
       "3        False    False  False  False      False       1  \n",
       "4        False    False  False  False      False       0  \n",
       "\n",
       "[5 rows x 63 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_comments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    29391\n",
       "1     2475\n",
       "Name: newcol, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check: Run these two lines below to confirm that they shape of newcol looks like perturbed_predictions array that you added\n",
    "test_comments['newcol'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2475"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(perturbed_predictions[0] == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** [(108.0, (45, 35)), (108.0, (45, 35)), (27.52258064516129, (1, 35)), (14.35483870967742, (1, 40)), (59.225806451612904, (1, 35)), (23.370967741935488, (1, 31)), (26.833333333333332, (48, 31)), (20.322580645161292, (1, 40)), (28.0, (45, 27)), (108.0, (45, 35))]\n"
     ]
    }
   ],
   "source": [
    "# For each of the perturbed_predictions, append it onto the dataset, find the pairwise DI, and then find the max DI.\n",
    "# Goal: Compute fairness on test dataset.\n",
    "\n",
    "test_data_dis = find_max_dis_of_perturbations(test_comments, perturbed_predictions, madlibs_terms)\n",
    "\n",
    "print(\"**\", test_data_dis)\n",
    "# This is the array of all of the max_dis, and the indexes of the madlibs_terms array that composed that max_di\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(108.0, (45, 35)), (108.0, (45, 35)), (27.52258064516129, (1, 35)), (14.35483870967742, (1, 40)), (59.225806451612904, (1, 35)), (23.370967741935488, (1, 31)), (26.833333333333332, (48, 31)), (20.322580645161292, (1, 40)), (28.0, (45, 27)), (108.0, (45, 35))]\n",
      "[(11.0, (7, 46)), (5.75, (7, 34)), (4.341696535244923, (1, 34)), (6.071428571428571, (7, 42)), (9.0, (7, 20)), (8.666666666666666, (7, 2)), (4.236363636363636, (7, 40)), (11.0, (7, 46)), (5.5, (7, 46)), (6.5, (7, 2))]\n",
      "[11.0, 5.75, 4.341696535244923, 6.071428571428571, 9.0, 8.666666666666666, 4.236363636363636, 11.0, 5.5, 6.5]\n",
      "[108.0, 108.0, 27.52258064516129, 14.35483870967742, 59.225806451612904, 23.370967741935488, 26.833333333333332, 20.322580645161292, 28.0, 108.0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x24e0032d5c0>]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# SO THATS IT\n",
    "# compare test_data_dis and training_data_dis for all 10 perturbation differences. \n",
    "\n",
    "print(test_data_dis)\n",
    "print(training_data_dis)\n",
    "\n",
    "training_xs = [item[0] for item in training_data_dis]\n",
    "test_ys = [item[0] for item in test_data_dis]\n",
    "\n",
    "print(training_xs)\n",
    "print(test_ys)\n",
    "\n",
    "plt.plot(training_xs, test_ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neha's notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"This data set (https://figshare.com/articles/Wikipedia_Talk_Labels_Toxicity/4563973) includes over 100k labeled discussion comments from English Wikipedia. Each comment was labeled by multiple annotators via Crowdflower on whether it is a toxic or healthy contribution. We also include some demographic data for each crowd-worker. See our wiki for documentation of the schema of each file and our research paper for documentation on the data collection and modeling methodology. For a quick demo of how to use the data for model building and analysis, check out this ipython notebook.\" - quote from linked page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = pd.read_csv(\"toxicity_annotated_comments.tsv\"\\\n",
    "                                          , sep = \"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copied from documentation: <br>\n",
    "\"Schema for {attack/aggression/toxicity}_annotated_comments.tsv\n",
    "The comment text and metadata for comments with attack/aggression/toxicity labels generated by crowd-workers. The actual labels are in the corresponding {attack/aggression/toxicity}_annotations.tsv since each comment was labeled multiple times.\n",
    "\n",
    "rev_id: MediaWiki revision id of the edit that added the comment to a talk page (i.e. discussion). <br>\n",
    "comment: Comment text. Consists of the concatenation of content added during a revision/edit of a talk page. MediaWiki markup and HTML have been stripped out. To simplify tsv parsing, \\n has been mapped to NEWLINE_TOKEN, \\t has been mapped to TAB_TOKEN and \" has been mapped to `. <br>\n",
    "year: The year the comment was posted in. <br>\n",
    "logged_in: Indicator for whether the user who made the comment was logged in. Takes on values in {0, 1}. <br>\n",
    "ns: Namespace of the discussion page the comment was made in. Takes on values in {user, article}. <br>\n",
    "sample: Indicates whether the comment came via random sampling of all comments, or whether it came from random sampling of the 5 comments around a block event for violating WP:npa or WP:HA. Takes on values in {random, blocked}. <br>\n",
    "split: For model building in our paper we split comments into train, dev and test sets. Takes on values in {train, dev, test}.\"\n",
    "<br>\n",
    "\n",
    "My notes: <br> \n",
    "I don't know enough about how natural language processing works, but from the snippets that I do know, I imagine that the really really long comments probably aren't very good at being classified even. I also wonder about how bigram toxicity works and whether this is something the training data accounts for (eg \"nasty woman\" vs \"nasty\" has different sources of problems). What are they classifying on/why does this work? We can see Figure 1 in the Dixon paper for comment length and should be able to filter there. I wonder if the phrase templating of classification works for the problems that I raise of large comment length and bigrams. Is this an issue we should be dealing with?\n",
    "Also, an easier couple of questions are: what does the ns and sample really mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rev_id</th>\n",
       "      <th>comment</th>\n",
       "      <th>year</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>ns</th>\n",
       "      <th>sample</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2232.0</td>\n",
       "      <td>This:NEWLINE_TOKEN:One can make an analogy in ...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4216.0</td>\n",
       "      <td>`NEWLINE_TOKENNEWLINE_TOKEN:Clarification for ...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8953.0</td>\n",
       "      <td>Elected or Electoral? JHK</td>\n",
       "      <td>2002</td>\n",
       "      <td>False</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26547.0</td>\n",
       "      <td>`This is such a fun entry.   DevotchkaNEWLINE_...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28959.0</td>\n",
       "      <td>Please relate the ozone hole to increases in c...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rev_id                                            comment  year  \\\n",
       "0   2232.0  This:NEWLINE_TOKEN:One can make an analogy in ...  2002   \n",
       "1   4216.0  `NEWLINE_TOKENNEWLINE_TOKEN:Clarification for ...  2002   \n",
       "2   8953.0                          Elected or Electoral? JHK  2002   \n",
       "3  26547.0  `This is such a fun entry.   DevotchkaNEWLINE_...  2002   \n",
       "4  28959.0  Please relate the ozone hole to increases in c...  2002   \n",
       "\n",
       "   logged_in       ns  sample  split  \n",
       "0       True  article  random  train  \n",
       "1       True     user  random  train  \n",
       "2      False  article  random   test  \n",
       "3       True  article  random  train  \n",
       "4       True  article  random   test  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copied from documentation:\n",
    "        Schema for toxicity_annotations.tsv\n",
    "    Toxicity labels from several crowd-workers for each comment in toxicity_annotated_comments.tsv. It can be joined with toxicity_annotated_comments.tsv on rev_id.\n",
    "\n",
    "rev_id: MediaWiki revision id of the edit that added the comment to a talk page (i.e. discussion). <br>\n",
    "worker_id: Anonymized crowd-worker id.<br>\n",
    "toxicity_score: Categorical variable ranging from very toxic (-2), to neutral (0), to very healthy (2). <br>\n",
    "toxicity: Indicator variable for whether the worker thought the comment is toxic. The annotation takes on the value 1 if the worker considered the comment toxic (i.e worker gave a toxicity_score less than 0) and value 0 if the worker considered the comment neutral or healthy (i.e worker gave a toxicity_score greater or equal to 0). Takes on values in {0, 1}.\n",
    "\n",
    "My notes:\n",
    "Things to explore is how many people rated each thing? The paper said 10, but I would like to confirm this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = pd.read_csv(\"toxicity_annotations.tsv\"\\\n",
    "                                          , sep = \"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My comment:\n",
    "    This isn't really one we'll be using until much later, if/when we decide we're doing a perturbation using demographic data. Would first want to check to see what kind of correlations might/do exist between gender/rating and see how they rate comments about women, for example.\n",
    "    \n",
    "\n",
    "Copied from documentation:\n",
    "\n",
    "Schema for {attack/aggression/toxicity}_worker_demographics.tsv\n",
    "Demographic information about the crowdworkers. This information was obtained by an optional demographic survey administered after the labelling task. It is meant to be joined with {attack/aggression/toxicity}_annotations.tsv on worker_id. Some fields may be blank if left unanswered.\n",
    "\n",
    "worker_id: Anonymized crowd-worker id. <br>\n",
    "gender: The gender of the crowd-worker. Takes a value in {'male', 'female', and 'other'}. <br>\n",
    "english_first_language: Does the crowd-worker describe English as their first language. Takes a value in {0, 1}.<br>\n",
    "age_group: The age group of the crowd-worker. Takes on values in {'Under 18', '18-30', '30-45', '45-60', 'Over 60'}.<br>\n",
    "education: The highest education level obtained by the crowd-worker. Takes on values in {'none', 'some', 'hs', 'bachelors', 'masters', 'doctorate', 'professional'}. Here 'none' means no schooling, some means 'some schooling', 'hs' means high school completion, and the remaining terms indicate completion of the corresponding degree type.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
